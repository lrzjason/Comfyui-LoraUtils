{
  "id": "00000000-0000-0000-0000-000000000000",
  "revision": 0,
  "last_node_id": 8,
  "last_link_id": 6,
  "nodes": [
    {
      "id": 1,
      "type": "LoadLoraOnly",
      "pos": [
        115.20001220703125,
        230.3599853515625
      ],
      "size": [
        387.1199951171875,
        58
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "lora_name",
          "name": "lora_name",
          "type": "COMBO",
          "widget": {
            "name": "lora_name"
          },
          "link": null
        }
      ],
      "outputs": [
        {
          "localized_name": "lora",
          "name": "lora",
          "type": "LORA",
          "links": [
            1,
            3
          ]
        }
      ],
      "properties": {
        "aux_id": "lrzjason/Comfyui-LoraUtils",
        "ver": "f6db1368facc26d491f90015d620f7b2b8e0c9f9",
        "Node name for S&R": "LoadLoraOnly"
      },
      "widgets_values": [
        "qwen\\handpick_json-19-24800.safetensors"
      ]
    },
    {
      "id": 5,
      "type": "LoraStatViewer",
      "pos": [
        536.3200073242188,
        425.56005859375
      ],
      "size": [
        179.58322143554688,
        26
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "lora",
          "name": "lora",
          "type": "LORA",
          "link": 3
        }
      ],
      "outputs": [
        {
          "localized_name": "lora_info",
          "name": "lora_info",
          "type": "STRING",
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "aux_id": "lrzjason/Comfyui-LoraUtils",
        "ver": "f6db1368facc26d491f90015d620f7b2b8e0c9f9",
        "Node name for S&R": "LoraStatViewer"
      }
    },
    {
      "id": 2,
      "type": "LoraLayersOperation",
      "pos": [
        530.5599365234375,
        232.9199981689453
      ],
      "size": [
        410.79998779296875,
        142.79998779296875
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "lora",
          "name": "lora",
          "type": "LORA",
          "link": 1
        },
        {
          "localized_name": "layer_pattern",
          "name": "layer_pattern",
          "type": "STRING",
          "widget": {
            "name": "layer_pattern"
          },
          "link": null
        },
        {
          "localized_name": "layer_indices",
          "name": "layer_indices",
          "type": "STRING",
          "widget": {
            "name": "layer_indices"
          },
          "link": null
        },
        {
          "localized_name": "scale_factor",
          "name": "scale_factor",
          "type": "FLOAT",
          "widget": {
            "name": "scale_factor"
          },
          "link": null
        }
      ],
      "outputs": [
        {
          "localized_name": "modified_lora",
          "name": "modified_lora",
          "type": "LORA",
          "links": [
            2
          ]
        }
      ],
      "properties": {
        "aux_id": "lrzjason/Comfyui-LoraUtils",
        "ver": "f6db1368facc26d491f90015d620f7b2b8e0c9f9",
        "Node name for S&R": "LoraLayersOperation"
      },
      "widgets_values": [
        ".*transformer_blocks\\.(\\d+)\\.",
        "49,50-59",
        0
      ]
    },
    {
      "id": 6,
      "type": "easy showAnything",
      "pos": [
        538.8800048828125,
        508.760009765625
      ],
      "size": [
        401.1199951171875,
        425.4400634765625
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "anything",
          "name": "anything",
          "shape": 7,
          "type": "*",
          "link": 4
        }
      ],
      "outputs": [
        {
          "localized_name": "output",
          "name": "output",
          "type": "*",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-easy-use",
        "ver": "e46f8a45d0f07558900eed0ad120d6ccbd0aab03",
        "Node name for S&R": "easy showAnything"
      },
      "widgets_values": [
        "=== LoRA Statistics ===\nTotal number of keys: 1200\n\nLayer types found in LoRA:\n  add_k_proj.lora_A.weight: 60 keys\n  add_k_proj.lora_B.weight: 60 keys\n  add_q_proj.lora_A.weight: 60 keys\n  add_q_proj.lora_B.weight: 60 keys\n  add_v_proj.lora_A.weight: 60 keys\n  add_v_proj.lora_B.weight: 60 keys\n  to_add_out.lora_A.weight: 60 keys\n  to_add_out.lora_B.weight: 60 keys\n  lora.down.weight: 240 keys\n  lora.up.weight: 240 keys\n  2.lora_A.weight: 120 keys\n  2.lora_B.weight: 120 keys\n\nFirst 10 keys (helpful for pattern creation):\n  [0] transformer.transformer_blocks.0.attn.add_k_proj.lora_A.weight\n  [1] transformer.transformer_blocks.0.attn.add_k_proj.lora_B.weight\n  [2] transformer.transformer_blocks.0.attn.add_q_proj.lora_A.weight\n  [3] transformer.transformer_blocks.0.attn.add_q_proj.lora_B.weight\n  [4] transformer.transformer_blocks.0.attn.add_v_proj.lora_A.weight\n  [5] transformer.transformer_blocks.0.attn.add_v_proj.lora_B.weight\n  [6] transformer.transformer_blocks.0.attn.to_add_out.lora_A.weight\n  [7] transformer.transformer_blocks.0.attn.to_add_out.lora_B.weight\n  [8] transformer.transformer_blocks.0.attn.to_k.lora.down.weight\n  [9] transformer.transformer_blocks.0.attn.to_k.lora.up.weight\n\nFound 1200 transformer block related keys\nTransformer block indices present: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n========================\n\nFull LoRA State Dictionary Keys:\n  [0] transformer.transformer_blocks.0.attn.add_k_proj.lora_A.weight\n  [1] transformer.transformer_blocks.0.attn.add_k_proj.lora_B.weight\n  [2] transformer.transformer_blocks.0.attn.add_q_proj.lora_A.weight\n  [3] transformer.transformer_blocks.0.attn.add_q_proj.lora_B.weight\n  [4] transformer.transformer_blocks.0.attn.add_v_proj.lora_A.weight\n  [5] transformer.transformer_blocks.0.attn.add_v_proj.lora_B.weight\n  [6] transformer.transformer_blocks.0.attn.to_add_out.lora_A.weight\n  [7] transformer.transformer_blocks.0.attn.to_add_out.lora_B.weight\n  [8] transformer.transformer_blocks.0.attn.to_k.lora.down.weight\n  [9] transformer.transformer_blocks.0.attn.to_k.lora.up.weight\n  [10] transformer.transformer_blocks.0.attn.to_out.0.lora.down.weight\n  [11] transformer.transformer_blocks.0.attn.to_out.0.lora.up.weight\n  [12] transformer.transformer_blocks.0.attn.to_q.lora.down.weight\n  [13] transformer.transformer_blocks.0.attn.to_q.lora.up.weight\n  [14] transformer.transformer_blocks.0.attn.to_v.lora.down.weight\n  [15] transformer.transformer_blocks.0.attn.to_v.lora.up.weight\n  [16] transformer.transformer_blocks.0.img_mlp.net.2.lora_A.weight\n  [17] transformer.transformer_blocks.0.img_mlp.net.2.lora_B.weight\n  [18] transformer.transformer_blocks.0.txt_mlp.net.2.lora_A.weight\n  [19] transformer.transformer_blocks.0.txt_mlp.net.2.lora_B.weight\n  [20] transformer.transformer_blocks.1.attn.add_k_proj.lora_A.weight\n  [21] transformer.transformer_blocks.1.attn.add_k_proj.lora_B.weight\n  [22] transformer.transformer_blocks.1.attn.add_q_proj.lora_A.weight\n  [23] transformer.transformer_blocks.1.attn.add_q_proj.lora_B.weight\n  [24] transformer.transformer_blocks.1.attn.add_v_proj.lora_A.weight\n  [25] transformer.transformer_blocks.1.attn.add_v_proj.lora_B.weight\n  [26] transformer.transformer_blocks.1.attn.to_add_out.lora_A.weight\n  [27] transformer.transformer_blocks.1.attn.to_add_out.lora_B.weight\n  [28] transformer.transformer_blocks.1.attn.to_k.lora.down.weight\n  [29] transformer.transformer_blocks.1.attn.to_k.lora.up.weight\n  [30] transformer.transformer_blocks.1.attn.to_out.0.lora.down.weight\n  [31] transformer.transformer_blocks.1.attn.to_out.0.lora.up.weight\n  [32] transformer.transformer_blocks.1.attn.to_q.lora.down.weight\n  [33] transformer.transformer_blocks.1.attn.to_q.lora.up.weight\n  [34] transformer.transformer_blocks.1.attn.to_v.lora.down.weight\n  [35] transformer.transformer_blocks.1.attn.to_v.lora.up.weight\n  [36] transformer.transformer_blocks.1.img_mlp.net.2.lora_A.weight\n  [37] transformer.transformer_blocks.1.img_mlp.net.2.lora_B.weight\n  [38] transformer.transformer_blocks.1.txt_mlp.net.2.lora_A.weight\n  [39] transformer.transformer_blocks.1.txt_mlp.net.2.lora_B.weight\n  [40] transformer.transformer_blocks.10.attn.add_k_proj.lora_A.weight\n  [41] transformer.transformer_blocks.10.attn.add_k_proj.lora_B.weight\n  [42] transformer.transformer_blocks.10.attn.add_q_proj.lora_A.weight\n  [43] transformer.transformer_blocks.10.attn.add_q_proj.lora_B.weight\n  [44] transformer.transformer_blocks.10.attn.add_v_proj.lora_A.weight\n  [45] transformer.transformer_blocks.10.attn.add_v_proj.lora_B.weight\n  [46] transformer.transformer_blocks.10.attn.to_add_out.lora_A.weight\n  [47] transformer.transformer_blocks.10.attn.to_add_out.lora_B.weight\n  [48] transformer.transformer_blocks.10.attn.to_k.lora.down.weight\n  [49] transformer.transformer_blocks.10.attn.to_k.lora.up.weight\n  [50] transformer.transformer_blocks.10.attn.to_out.0.lora.down.weight\n  [51] transformer.transformer_blocks.10.attn.to_out.0.lora.up.weight\n  [52] transformer.transformer_blocks.10.attn.to_q.lora.down.weight\n  [53] transformer.transformer_blocks.10.attn.to_q.lora.up.weight\n  [54] transformer.transformer_blocks.10.attn.to_v.lora.down.weight\n  [55] transformer.transformer_blocks.10.attn.to_v.lora.up.weight\n  [56] transformer.transformer_blocks.10.img_mlp.net.2.lora_A.weight\n  [57] transformer.transformer_blocks.10.img_mlp.net.2.lora_B.weight\n  [58] transformer.transformer_blocks.10.txt_mlp.net.2.lora_A.weight\n  [59] transformer.transformer_blocks.10.txt_mlp.net.2.lora_B.weight\n  [60] transformer.transformer_blocks.11.attn.add_k_proj.lora_A.weight\n  [61] transformer.transformer_blocks.11.attn.add_k_proj.lora_B.weight\n  [62] transformer.transformer_blocks.11.attn.add_q_proj.lora_A.weight\n  [63] transformer.transformer_blocks.11.attn.add_q_proj.lora_B.weight\n  [64] transformer.transformer_blocks.11.attn.add_v_proj.lora_A.weight\n  [65] transformer.transformer_blocks.11.attn.add_v_proj.lora_B.weight\n  [66] transformer.transformer_blocks.11.attn.to_add_out.lora_A.weight\n  [67] transformer.transformer_blocks.11.attn.to_add_out.lora_B.weight\n  [68] transformer.transformer_blocks.11.attn.to_k.lora.down.weight\n  [69] transformer.transformer_blocks.11.attn.to_k.lora.up.weight\n  [70] transformer.transformer_blocks.11.attn.to_out.0.lora.down.weight\n  [71] transformer.transformer_blocks.11.attn.to_out.0.lora.up.weight\n  [72] transformer.transformer_blocks.11.attn.to_q.lora.down.weight\n  [73] transformer.transformer_blocks.11.attn.to_q.lora.up.weight\n  [74] transformer.transformer_blocks.11.attn.to_v.lora.down.weight\n  [75] transformer.transformer_blocks.11.attn.to_v.lora.up.weight\n  [76] transformer.transformer_blocks.11.img_mlp.net.2.lora_A.weight\n  [77] transformer.transformer_blocks.11.img_mlp.net.2.lora_B.weight\n  [78] transformer.transformer_blocks.11.txt_mlp.net.2.lora_A.weight\n  [79] transformer.transformer_blocks.11.txt_mlp.net.2.lora_B.weight\n  [80] transformer.transformer_blocks.12.attn.add_k_proj.lora_A.weight\n  [81] transformer.transformer_blocks.12.attn.add_k_proj.lora_B.weight\n  [82] transformer.transformer_blocks.12.attn.add_q_proj.lora_A.weight\n  [83] transformer.transformer_blocks.12.attn.add_q_proj.lora_B.weight\n  [84] transformer.transformer_blocks.12.attn.add_v_proj.lora_A.weight\n  [85] transformer.transformer_blocks.12.attn.add_v_proj.lora_B.weight\n  [86] transformer.transformer_blocks.12.attn.to_add_out.lora_A.weight\n  [87] transformer.transformer_blocks.12.attn.to_add_out.lora_B.weight\n  [88] transformer.transformer_blocks.12.attn.to_k.lora.down.weight\n  [89] transformer.transformer_blocks.12.attn.to_k.lora.up.weight\n  [90] transformer.transformer_blocks.12.attn.to_out.0.lora.down.weight\n  [91] transformer.transformer_blocks.12.attn.to_out.0.lora.up.weight\n  [92] transformer.transformer_blocks.12.attn.to_q.lora.down.weight\n  [93] transformer.transformer_blocks.12.attn.to_q.lora.up.weight\n  [94] transformer.transformer_blocks.12.attn.to_v.lora.down.weight\n  [95] transformer.transformer_blocks.12.attn.to_v.lora.up.weight\n  [96] transformer.transformer_blocks.12.img_mlp.net.2.lora_A.weight\n  [97] transformer.transformer_blocks.12.img_mlp.net.2.lora_B.weight\n  [98] transformer.transformer_blocks.12.txt_mlp.net.2.lora_A.weight\n  [99] transformer.transformer_blocks.12.txt_mlp.net.2.lora_B.weight\n  [100] transformer.transformer_blocks.13.attn.add_k_proj.lora_A.weight\n  [101] transformer.transformer_blocks.13.attn.add_k_proj.lora_B.weight\n  [102] transformer.transformer_blocks.13.attn.add_q_proj.lora_A.weight\n  [103] transformer.transformer_blocks.13.attn.add_q_proj.lora_B.weight\n  [104] transformer.transformer_blocks.13.attn.add_v_proj.lora_A.weight\n  [105] transformer.transformer_blocks.13.attn.add_v_proj.lora_B.weight\n  [106] transformer.transformer_blocks.13.attn.to_add_out.lora_A.weight\n  [107] transformer.transformer_blocks.13.attn.to_add_out.lora_B.weight\n  [108] transformer.transformer_blocks.13.attn.to_k.lora.down.weight\n  [109] transformer.transformer_blocks.13.attn.to_k.lora.up.weight\n  [110] transformer.transformer_blocks.13.attn.to_out.0.lora.down.weight\n  [111] transformer.transformer_blocks.13.attn.to_out.0.lora.up.weight\n  [112] transformer.transformer_blocks.13.attn.to_q.lora.down.weight\n  [113] transformer.transformer_blocks.13.attn.to_q.lora.up.weight\n  [114] transformer.transformer_blocks.13.attn.to_v.lora.down.weight\n  [115] transformer.transformer_blocks.13.attn.to_v.lora.up.weight\n  [116] transformer.transformer_blocks.13.img_mlp.net.2.lora_A.weight\n  [117] transformer.transformer_blocks.13.img_mlp.net.2.lora_B.weight\n  [118] transformer.transformer_blocks.13.txt_mlp.net.2.lora_A.weight\n  [119] transformer.transformer_blocks.13.txt_mlp.net.2.lora_B.weight\n  [120] transformer.transformer_blocks.14.attn.add_k_proj.lora_A.weight\n  [121] transformer.transformer_blocks.14.attn.add_k_proj.lora_B.weight\n  [122] transformer.transformer_blocks.14.attn.add_q_proj.lora_A.weight\n  [123] transformer.transformer_blocks.14.attn.add_q_proj.lora_B.weight\n  [124] transformer.transformer_blocks.14.attn.add_v_proj.lora_A.weight\n  [125] transformer.transformer_blocks.14.attn.add_v_proj.lora_B.weight\n  [126] transformer.transformer_blocks.14.attn.to_add_out.lora_A.weight\n  [127] transformer.transformer_blocks.14.attn.to_add_out.lora_B.weight\n  [128] transformer.transformer_blocks.14.attn.to_k.lora.down.weight\n  [129] transformer.transformer_blocks.14.attn.to_k.lora.up.weight\n  [130] transformer.transformer_blocks.14.attn.to_out.0.lora.down.weight\n  [131] transformer.transformer_blocks.14.attn.to_out.0.lora.up.weight\n  [132] transformer.transformer_blocks.14.attn.to_q.lora.down.weight\n  [133] transformer.transformer_blocks.14.attn.to_q.lora.up.weight\n  [134] transformer.transformer_blocks.14.attn.to_v.lora.down.weight\n  [135] transformer.transformer_blocks.14.attn.to_v.lora.up.weight\n  [136] transformer.transformer_blocks.14.img_mlp.net.2.lora_A.weight\n  [137] transformer.transformer_blocks.14.img_mlp.net.2.lora_B.weight\n  [138] transformer.transformer_blocks.14.txt_mlp.net.2.lora_A.weight\n  [139] transformer.transformer_blocks.14.txt_mlp.net.2.lora_B.weight\n  [140] transformer.transformer_blocks.15.attn.add_k_proj.lora_A.weight\n  [141] transformer.transformer_blocks.15.attn.add_k_proj.lora_B.weight\n  [142] transformer.transformer_blocks.15.attn.add_q_proj.lora_A.weight\n  [143] transformer.transformer_blocks.15.attn.add_q_proj.lora_B.weight\n  [144] transformer.transformer_blocks.15.attn.add_v_proj.lora_A.weight\n  [145] transformer.transformer_blocks.15.attn.add_v_proj.lora_B.weight\n  [146] transformer.transformer_blocks.15.attn.to_add_out.lora_A.weight\n  [147] transformer.transformer_blocks.15.attn.to_add_out.lora_B.weight\n  [148] transformer.transformer_blocks.15.attn.to_k.lora.down.weight\n  [149] transformer.transformer_blocks.15.attn.to_k.lora.up.weight\n  [150] transformer.transformer_blocks.15.attn.to_out.0.lora.down.weight\n  [151] transformer.transformer_blocks.15.attn.to_out.0.lora.up.weight\n  [152] transformer.transformer_blocks.15.attn.to_q.lora.down.weight\n  [153] transformer.transformer_blocks.15.attn.to_q.lora.up.weight\n  [154] transformer.transformer_blocks.15.attn.to_v.lora.down.weight\n  [155] transformer.transformer_blocks.15.attn.to_v.lora.up.weight\n  [156] transformer.transformer_blocks.15.img_mlp.net.2.lora_A.weight\n  [157] transformer.transformer_blocks.15.img_mlp.net.2.lora_B.weight\n  [158] transformer.transformer_blocks.15.txt_mlp.net.2.lora_A.weight\n  [159] transformer.transformer_blocks.15.txt_mlp.net.2.lora_B.weight\n  [160] transformer.transformer_blocks.16.attn.add_k_proj.lora_A.weight\n  [161] transformer.transformer_blocks.16.attn.add_k_proj.lora_B.weight\n  [162] transformer.transformer_blocks.16.attn.add_q_proj.lora_A.weight\n  [163] transformer.transformer_blocks.16.attn.add_q_proj.lora_B.weight\n  [164] transformer.transformer_blocks.16.attn.add_v_proj.lora_A.weight\n  [165] transformer.transformer_blocks.16.attn.add_v_proj.lora_B.weight\n  [166] transformer.transformer_blocks.16.attn.to_add_out.lora_A.weight\n  [167] transformer.transformer_blocks.16.attn.to_add_out.lora_B.weight\n  [168] transformer.transformer_blocks.16.attn.to_k.lora.down.weight\n  [169] transformer.transformer_blocks.16.attn.to_k.lora.up.weight\n  [170] transformer.transformer_blocks.16.attn.to_out.0.lora.down.weight\n  [171] transformer.transformer_blocks.16.attn.to_out.0.lora.up.weight\n  [172] transformer.transformer_blocks.16.attn.to_q.lora.down.weight\n  [173] transformer.transformer_blocks.16.attn.to_q.lora.up.weight\n  [174] transformer.transformer_blocks.16.attn.to_v.lora.down.weight\n  [175] transformer.transformer_blocks.16.attn.to_v.lora.up.weight\n  [176] transformer.transformer_blocks.16.img_mlp.net.2.lora_A.weight\n  [177] transformer.transformer_blocks.16.img_mlp.net.2.lora_B.weight\n  [178] transformer.transformer_blocks.16.txt_mlp.net.2.lora_A.weight\n  [179] transformer.transformer_blocks.16.txt_mlp.net.2.lora_B.weight\n  [180] transformer.transformer_blocks.17.attn.add_k_proj.lora_A.weight\n  [181] transformer.transformer_blocks.17.attn.add_k_proj.lora_B.weight\n  [182] transformer.transformer_blocks.17.attn.add_q_proj.lora_A.weight\n  [183] transformer.transformer_blocks.17.attn.add_q_proj.lora_B.weight\n  [184] transformer.transformer_blocks.17.attn.add_v_proj.lora_A.weight\n  [185] transformer.transformer_blocks.17.attn.add_v_proj.lora_B.weight\n  [186] transformer.transformer_blocks.17.attn.to_add_out.lora_A.weight\n  [187] transformer.transformer_blocks.17.attn.to_add_out.lora_B.weight\n  [188] transformer.transformer_blocks.17.attn.to_k.lora.down.weight\n  [189] transformer.transformer_blocks.17.attn.to_k.lora.up.weight\n  [190] transformer.transformer_blocks.17.attn.to_out.0.lora.down.weight\n  [191] transformer.transformer_blocks.17.attn.to_out.0.lora.up.weight\n  [192] transformer.transformer_blocks.17.attn.to_q.lora.down.weight\n  [193] transformer.transformer_blocks.17.attn.to_q.lora.up.weight\n  [194] transformer.transformer_blocks.17.attn.to_v.lora.down.weight\n  [195] transformer.transformer_blocks.17.attn.to_v.lora.up.weight\n  [196] transformer.transformer_blocks.17.img_mlp.net.2.lora_A.weight\n  [197] transformer.transformer_blocks.17.img_mlp.net.2.lora_B.weight\n  [198] transformer.transformer_blocks.17.txt_mlp.net.2.lora_A.weight\n  [199] transformer.transformer_blocks.17.txt_mlp.net.2.lora_B.weight\n  [200] transformer.transformer_blocks.18.attn.add_k_proj.lora_A.weight\n  [201] transformer.transformer_blocks.18.attn.add_k_proj.lora_B.weight\n  [202] transformer.transformer_blocks.18.attn.add_q_proj.lora_A.weight\n  [203] transformer.transformer_blocks.18.attn.add_q_proj.lora_B.weight\n  [204] transformer.transformer_blocks.18.attn.add_v_proj.lora_A.weight\n  [205] transformer.transformer_blocks.18.attn.add_v_proj.lora_B.weight\n  [206] transformer.transformer_blocks.18.attn.to_add_out.lora_A.weight\n  [207] transformer.transformer_blocks.18.attn.to_add_out.lora_B.weight\n  [208] transformer.transformer_blocks.18.attn.to_k.lora.down.weight\n  [209] transformer.transformer_blocks.18.attn.to_k.lora.up.weight\n  [210] transformer.transformer_blocks.18.attn.to_out.0.lora.down.weight\n  [211] transformer.transformer_blocks.18.attn.to_out.0.lora.up.weight\n  [212] transformer.transformer_blocks.18.attn.to_q.lora.down.weight\n  [213] transformer.transformer_blocks.18.attn.to_q.lora.up.weight\n  [214] transformer.transformer_blocks.18.attn.to_v.lora.down.weight\n  [215] transformer.transformer_blocks.18.attn.to_v.lora.up.weight\n  [216] transformer.transformer_blocks.18.img_mlp.net.2.lora_A.weight\n  [217] transformer.transformer_blocks.18.img_mlp.net.2.lora_B.weight\n  [218] transformer.transformer_blocks.18.txt_mlp.net.2.lora_A.weight\n  [219] transformer.transformer_blocks.18.txt_mlp.net.2.lora_B.weight\n  [220] transformer.transformer_blocks.19.attn.add_k_proj.lora_A.weight\n  [221] transformer.transformer_blocks.19.attn.add_k_proj.lora_B.weight\n  [222] transformer.transformer_blocks.19.attn.add_q_proj.lora_A.weight\n  [223] transformer.transformer_blocks.19.attn.add_q_proj.lora_B.weight\n  [224] transformer.transformer_blocks.19.attn.add_v_proj.lora_A.weight\n  [225] transformer.transformer_blocks.19.attn.add_v_proj.lora_B.weight\n  [226] transformer.transformer_blocks.19.attn.to_add_out.lora_A.weight\n  [227] transformer.transformer_blocks.19.attn.to_add_out.lora_B.weight\n  [228] transformer.transformer_blocks.19.attn.to_k.lora.down.weight\n  [229] transformer.transformer_blocks.19.attn.to_k.lora.up.weight\n  [230] transformer.transformer_blocks.19.attn.to_out.0.lora.down.weight\n  [231] transformer.transformer_blocks.19.attn.to_out.0.lora.up.weight\n  [232] transformer.transformer_blocks.19.attn.to_q.lora.down.weight\n  [233] transformer.transformer_blocks.19.attn.to_q.lora.up.weight\n  [234] transformer.transformer_blocks.19.attn.to_v.lora.down.weight\n  [235] transformer.transformer_blocks.19.attn.to_v.lora.up.weight\n  [236] transformer.transformer_blocks.19.img_mlp.net.2.lora_A.weight\n  [237] transformer.transformer_blocks.19.img_mlp.net.2.lora_B.weight\n  [238] transformer.transformer_blocks.19.txt_mlp.net.2.lora_A.weight\n  [239] transformer.transformer_blocks.19.txt_mlp.net.2.lora_B.weight\n  [240] transformer.transformer_blocks.2.attn.add_k_proj.lora_A.weight\n  [241] transformer.transformer_blocks.2.attn.add_k_proj.lora_B.weight\n  [242] transformer.transformer_blocks.2.attn.add_q_proj.lora_A.weight\n  [243] transformer.transformer_blocks.2.attn.add_q_proj.lora_B.weight\n  [244] transformer.transformer_blocks.2.attn.add_v_proj.lora_A.weight\n  [245] transformer.transformer_blocks.2.attn.add_v_proj.lora_B.weight\n  [246] transformer.transformer_blocks.2.attn.to_add_out.lora_A.weight\n  [247] transformer.transformer_blocks.2.attn.to_add_out.lora_B.weight\n  [248] transformer.transformer_blocks.2.attn.to_k.lora.down.weight\n  [249] transformer.transformer_blocks.2.attn.to_k.lora.up.weight\n  [250] transformer.transformer_blocks.2.attn.to_out.0.lora.down.weight\n  [251] transformer.transformer_blocks.2.attn.to_out.0.lora.up.weight\n  [252] transformer.transformer_blocks.2.attn.to_q.lora.down.weight\n  [253] transformer.transformer_blocks.2.attn.to_q.lora.up.weight\n  [254] transformer.transformer_blocks.2.attn.to_v.lora.down.weight\n  [255] transformer.transformer_blocks.2.attn.to_v.lora.up.weight\n  [256] transformer.transformer_blocks.2.img_mlp.net.2.lora_A.weight\n  [257] transformer.transformer_blocks.2.img_mlp.net.2.lora_B.weight\n  [258] transformer.transformer_blocks.2.txt_mlp.net.2.lora_A.weight\n  [259] transformer.transformer_blocks.2.txt_mlp.net.2.lora_B.weight\n  [260] transformer.transformer_blocks.20.attn.add_k_proj.lora_A.weight\n  [261] transformer.transformer_blocks.20.attn.add_k_proj.lora_B.weight\n  [262] transformer.transformer_blocks.20.attn.add_q_proj.lora_A.weight\n  [263] transformer.transformer_blocks.20.attn.add_q_proj.lora_B.weight\n  [264] transformer.transformer_blocks.20.attn.add_v_proj.lora_A.weight\n  [265] transformer.transformer_blocks.20.attn.add_v_proj.lora_B.weight\n  [266] transformer.transformer_blocks.20.attn.to_add_out.lora_A.weight\n  [267] transformer.transformer_blocks.20.attn.to_add_out.lora_B.weight\n  [268] transformer.transformer_blocks.20.attn.to_k.lora.down.weight\n  [269] transformer.transformer_blocks.20.attn.to_k.lora.up.weight\n  [270] transformer.transformer_blocks.20.attn.to_out.0.lora.down.weight\n  [271] transformer.transformer_blocks.20.attn.to_out.0.lora.up.weight\n  [272] transformer.transformer_blocks.20.attn.to_q.lora.down.weight\n  [273] transformer.transformer_blocks.20.attn.to_q.lora.up.weight\n  [274] transformer.transformer_blocks.20.attn.to_v.lora.down.weight\n  [275] transformer.transformer_blocks.20.attn.to_v.lora.up.weight\n  [276] transformer.transformer_blocks.20.img_mlp.net.2.lora_A.weight\n  [277] transformer.transformer_blocks.20.img_mlp.net.2.lora_B.weight\n  [278] transformer.transformer_blocks.20.txt_mlp.net.2.lora_A.weight\n  [279] transformer.transformer_blocks.20.txt_mlp.net.2.lora_B.weight\n  [280] transformer.transformer_blocks.21.attn.add_k_proj.lora_A.weight\n  [281] transformer.transformer_blocks.21.attn.add_k_proj.lora_B.weight\n  [282] transformer.transformer_blocks.21.attn.add_q_proj.lora_A.weight\n  [283] transformer.transformer_blocks.21.attn.add_q_proj.lora_B.weight\n  [284] transformer.transformer_blocks.21.attn.add_v_proj.lora_A.weight\n  [285] transformer.transformer_blocks.21.attn.add_v_proj.lora_B.weight\n  [286] transformer.transformer_blocks.21.attn.to_add_out.lora_A.weight\n  [287] transformer.transformer_blocks.21.attn.to_add_out.lora_B.weight\n  [288] transformer.transformer_blocks.21.attn.to_k.lora.down.weight\n  [289] transformer.transformer_blocks.21.attn.to_k.lora.up.weight\n  [290] transformer.transformer_blocks.21.attn.to_out.0.lora.down.weight\n  [291] transformer.transformer_blocks.21.attn.to_out.0.lora.up.weight\n  [292] transformer.transformer_blocks.21.attn.to_q.lora.down.weight\n  [293] transformer.transformer_blocks.21.attn.to_q.lora.up.weight\n  [294] transformer.transformer_blocks.21.attn.to_v.lora.down.weight\n  [295] transformer.transformer_blocks.21.attn.to_v.lora.up.weight\n  [296] transformer.transformer_blocks.21.img_mlp.net.2.lora_A.weight\n  [297] transformer.transformer_blocks.21.img_mlp.net.2.lora_B.weight\n  [298] transformer.transformer_blocks.21.txt_mlp.net.2.lora_A.weight\n  [299] transformer.transformer_blocks.21.txt_mlp.net.2.lora_B.weight\n  [300] transformer.transformer_blocks.22.attn.add_k_proj.lora_A.weight\n  [301] transformer.transformer_blocks.22.attn.add_k_proj.lora_B.weight\n  [302] transformer.transformer_blocks.22.attn.add_q_proj.lora_A.weight\n  [303] transformer.transformer_blocks.22.attn.add_q_proj.lora_B.weight\n  [304] transformer.transformer_blocks.22.attn.add_v_proj.lora_A.weight\n  [305] transformer.transformer_blocks.22.attn.add_v_proj.lora_B.weight\n  [306] transformer.transformer_blocks.22.attn.to_add_out.lora_A.weight\n  [307] transformer.transformer_blocks.22.attn.to_add_out.lora_B.weight\n  [308] transformer.transformer_blocks.22.attn.to_k.lora.down.weight\n  [309] transformer.transformer_blocks.22.attn.to_k.lora.up.weight\n  [310] transformer.transformer_blocks.22.attn.to_out.0.lora.down.weight\n  [311] transformer.transformer_blocks.22.attn.to_out.0.lora.up.weight\n  [312] transformer.transformer_blocks.22.attn.to_q.lora.down.weight\n  [313] transformer.transformer_blocks.22.attn.to_q.lora.up.weight\n  [314] transformer.transformer_blocks.22.attn.to_v.lora.down.weight\n  [315] transformer.transformer_blocks.22.attn.to_v.lora.up.weight\n  [316] transformer.transformer_blocks.22.img_mlp.net.2.lora_A.weight\n  [317] transformer.transformer_blocks.22.img_mlp.net.2.lora_B.weight\n  [318] transformer.transformer_blocks.22.txt_mlp.net.2.lora_A.weight\n  [319] transformer.transformer_blocks.22.txt_mlp.net.2.lora_B.weight\n  [320] transformer.transformer_blocks.23.attn.add_k_proj.lora_A.weight\n  [321] transformer.transformer_blocks.23.attn.add_k_proj.lora_B.weight\n  [322] transformer.transformer_blocks.23.attn.add_q_proj.lora_A.weight\n  [323] transformer.transformer_blocks.23.attn.add_q_proj.lora_B.weight\n  [324] transformer.transformer_blocks.23.attn.add_v_proj.lora_A.weight\n  [325] transformer.transformer_blocks.23.attn.add_v_proj.lora_B.weight\n  [326] transformer.transformer_blocks.23.attn.to_add_out.lora_A.weight\n  [327] transformer.transformer_blocks.23.attn.to_add_out.lora_B.weight\n  [328] transformer.transformer_blocks.23.attn.to_k.lora.down.weight\n  [329] transformer.transformer_blocks.23.attn.to_k.lora.up.weight\n  [330] transformer.transformer_blocks.23.attn.to_out.0.lora.down.weight\n  [331] transformer.transformer_blocks.23.attn.to_out.0.lora.up.weight\n  [332] transformer.transformer_blocks.23.attn.to_q.lora.down.weight\n  [333] transformer.transformer_blocks.23.attn.to_q.lora.up.weight\n  [334] transformer.transformer_blocks.23.attn.to_v.lora.down.weight\n  [335] transformer.transformer_blocks.23.attn.to_v.lora.up.weight\n  [336] transformer.transformer_blocks.23.img_mlp.net.2.lora_A.weight\n  [337] transformer.transformer_blocks.23.img_mlp.net.2.lora_B.weight\n  [338] transformer.transformer_blocks.23.txt_mlp.net.2.lora_A.weight\n  [339] transformer.transformer_blocks.23.txt_mlp.net.2.lora_B.weight\n  [340] transformer.transformer_blocks.24.attn.add_k_proj.lora_A.weight\n  [341] transformer.transformer_blocks.24.attn.add_k_proj.lora_B.weight\n  [342] transformer.transformer_blocks.24.attn.add_q_proj.lora_A.weight\n  [343] transformer.transformer_blocks.24.attn.add_q_proj.lora_B.weight\n  [344] transformer.transformer_blocks.24.attn.add_v_proj.lora_A.weight\n  [345] transformer.transformer_blocks.24.attn.add_v_proj.lora_B.weight\n  [346] transformer.transformer_blocks.24.attn.to_add_out.lora_A.weight\n  [347] transformer.transformer_blocks.24.attn.to_add_out.lora_B.weight\n  [348] transformer.transformer_blocks.24.attn.to_k.lora.down.weight\n  [349] transformer.transformer_blocks.24.attn.to_k.lora.up.weight\n  [350] transformer.transformer_blocks.24.attn.to_out.0.lora.down.weight\n  [351] transformer.transformer_blocks.24.attn.to_out.0.lora.up.weight\n  [352] transformer.transformer_blocks.24.attn.to_q.lora.down.weight\n  [353] transformer.transformer_blocks.24.attn.to_q.lora.up.weight\n  [354] transformer.transformer_blocks.24.attn.to_v.lora.down.weight\n  [355] transformer.transformer_blocks.24.attn.to_v.lora.up.weight\n  [356] transformer.transformer_blocks.24.img_mlp.net.2.lora_A.weight\n  [357] transformer.transformer_blocks.24.img_mlp.net.2.lora_B.weight\n  [358] transformer.transformer_blocks.24.txt_mlp.net.2.lora_A.weight\n  [359] transformer.transformer_blocks.24.txt_mlp.net.2.lora_B.weight\n  [360] transformer.transformer_blocks.25.attn.add_k_proj.lora_A.weight\n  [361] transformer.transformer_blocks.25.attn.add_k_proj.lora_B.weight\n  [362] transformer.transformer_blocks.25.attn.add_q_proj.lora_A.weight\n  [363] transformer.transformer_blocks.25.attn.add_q_proj.lora_B.weight\n  [364] transformer.transformer_blocks.25.attn.add_v_proj.lora_A.weight\n  [365] transformer.transformer_blocks.25.attn.add_v_proj.lora_B.weight\n  [366] transformer.transformer_blocks.25.attn.to_add_out.lora_A.weight\n  [367] transformer.transformer_blocks.25.attn.to_add_out.lora_B.weight\n  [368] transformer.transformer_blocks.25.attn.to_k.lora.down.weight\n  [369] transformer.transformer_blocks.25.attn.to_k.lora.up.weight\n  [370] transformer.transformer_blocks.25.attn.to_out.0.lora.down.weight\n  [371] transformer.transformer_blocks.25.attn.to_out.0.lora.up.weight\n  [372] transformer.transformer_blocks.25.attn.to_q.lora.down.weight\n  [373] transformer.transformer_blocks.25.attn.to_q.lora.up.weight\n  [374] transformer.transformer_blocks.25.attn.to_v.lora.down.weight\n  [375] transformer.transformer_blocks.25.attn.to_v.lora.up.weight\n  [376] transformer.transformer_blocks.25.img_mlp.net.2.lora_A.weight\n  [377] transformer.transformer_blocks.25.img_mlp.net.2.lora_B.weight\n  [378] transformer.transformer_blocks.25.txt_mlp.net.2.lora_A.weight\n  [379] transformer.transformer_blocks.25.txt_mlp.net.2.lora_B.weight\n  [380] transformer.transformer_blocks.26.attn.add_k_proj.lora_A.weight\n  [381] transformer.transformer_blocks.26.attn.add_k_proj.lora_B.weight\n  [382] transformer.transformer_blocks.26.attn.add_q_proj.lora_A.weight\n  [383] transformer.transformer_blocks.26.attn.add_q_proj.lora_B.weight\n  [384] transformer.transformer_blocks.26.attn.add_v_proj.lora_A.weight\n  [385] transformer.transformer_blocks.26.attn.add_v_proj.lora_B.weight\n  [386] transformer.transformer_blocks.26.attn.to_add_out.lora_A.weight\n  [387] transformer.transformer_blocks.26.attn.to_add_out.lora_B.weight\n  [388] transformer.transformer_blocks.26.attn.to_k.lora.down.weight\n  [389] transformer.transformer_blocks.26.attn.to_k.lora.up.weight\n  [390] transformer.transformer_blocks.26.attn.to_out.0.lora.down.weight\n  [391] transformer.transformer_blocks.26.attn.to_out.0.lora.up.weight\n  [392] transformer.transformer_blocks.26.attn.to_q.lora.down.weight\n  [393] transformer.transformer_blocks.26.attn.to_q.lora.up.weight\n  [394] transformer.transformer_blocks.26.attn.to_v.lora.down.weight\n  [395] transformer.transformer_blocks.26.attn.to_v.lora.up.weight\n  [396] transformer.transformer_blocks.26.img_mlp.net.2.lora_A.weight\n  [397] transformer.transformer_blocks.26.img_mlp.net.2.lora_B.weight\n  [398] transformer.transformer_blocks.26.txt_mlp.net.2.lora_A.weight\n  [399] transformer.transformer_blocks.26.txt_mlp.net.2.lora_B.weight\n  [400] transformer.transformer_blocks.27.attn.add_k_proj.lora_A.weight\n  [401] transformer.transformer_blocks.27.attn.add_k_proj.lora_B.weight\n  [402] transformer.transformer_blocks.27.attn.add_q_proj.lora_A.weight\n  [403] transformer.transformer_blocks.27.attn.add_q_proj.lora_B.weight\n  [404] transformer.transformer_blocks.27.attn.add_v_proj.lora_A.weight\n  [405] transformer.transformer_blocks.27.attn.add_v_proj.lora_B.weight\n  [406] transformer.transformer_blocks.27.attn.to_add_out.lora_A.weight\n  [407] transformer.transformer_blocks.27.attn.to_add_out.lora_B.weight\n  [408] transformer.transformer_blocks.27.attn.to_k.lora.down.weight\n  [409] transformer.transformer_blocks.27.attn.to_k.lora.up.weight\n  [410] transformer.transformer_blocks.27.attn.to_out.0.lora.down.weight\n  [411] transformer.transformer_blocks.27.attn.to_out.0.lora.up.weight\n  [412] transformer.transformer_blocks.27.attn.to_q.lora.down.weight\n  [413] transformer.transformer_blocks.27.attn.to_q.lora.up.weight\n  [414] transformer.transformer_blocks.27.attn.to_v.lora.down.weight\n  [415] transformer.transformer_blocks.27.attn.to_v.lora.up.weight\n  [416] transformer.transformer_blocks.27.img_mlp.net.2.lora_A.weight\n  [417] transformer.transformer_blocks.27.img_mlp.net.2.lora_B.weight\n  [418] transformer.transformer_blocks.27.txt_mlp.net.2.lora_A.weight\n  [419] transformer.transformer_blocks.27.txt_mlp.net.2.lora_B.weight\n  [420] transformer.transformer_blocks.28.attn.add_k_proj.lora_A.weight\n  [421] transformer.transformer_blocks.28.attn.add_k_proj.lora_B.weight\n  [422] transformer.transformer_blocks.28.attn.add_q_proj.lora_A.weight\n  [423] transformer.transformer_blocks.28.attn.add_q_proj.lora_B.weight\n  [424] transformer.transformer_blocks.28.attn.add_v_proj.lora_A.weight\n  [425] transformer.transformer_blocks.28.attn.add_v_proj.lora_B.weight\n  [426] transformer.transformer_blocks.28.attn.to_add_out.lora_A.weight\n  [427] transformer.transformer_blocks.28.attn.to_add_out.lora_B.weight\n  [428] transformer.transformer_blocks.28.attn.to_k.lora.down.weight\n  [429] transformer.transformer_blocks.28.attn.to_k.lora.up.weight\n  [430] transformer.transformer_blocks.28.attn.to_out.0.lora.down.weight\n  [431] transformer.transformer_blocks.28.attn.to_out.0.lora.up.weight\n  [432] transformer.transformer_blocks.28.attn.to_q.lora.down.weight\n  [433] transformer.transformer_blocks.28.attn.to_q.lora.up.weight\n  [434] transformer.transformer_blocks.28.attn.to_v.lora.down.weight\n  [435] transformer.transformer_blocks.28.attn.to_v.lora.up.weight\n  [436] transformer.transformer_blocks.28.img_mlp.net.2.lora_A.weight\n  [437] transformer.transformer_blocks.28.img_mlp.net.2.lora_B.weight\n  [438] transformer.transformer_blocks.28.txt_mlp.net.2.lora_A.weight\n  [439] transformer.transformer_blocks.28.txt_mlp.net.2.lora_B.weight\n  [440] transformer.transformer_blocks.29.attn.add_k_proj.lora_A.weight\n  [441] transformer.transformer_blocks.29.attn.add_k_proj.lora_B.weight\n  [442] transformer.transformer_blocks.29.attn.add_q_proj.lora_A.weight\n  [443] transformer.transformer_blocks.29.attn.add_q_proj.lora_B.weight\n  [444] transformer.transformer_blocks.29.attn.add_v_proj.lora_A.weight\n  [445] transformer.transformer_blocks.29.attn.add_v_proj.lora_B.weight\n  [446] transformer.transformer_blocks.29.attn.to_add_out.lora_A.weight\n  [447] transformer.transformer_blocks.29.attn.to_add_out.lora_B.weight\n  [448] transformer.transformer_blocks.29.attn.to_k.lora.down.weight\n  [449] transformer.transformer_blocks.29.attn.to_k.lora.up.weight\n  [450] transformer.transformer_blocks.29.attn.to_out.0.lora.down.weight\n  [451] transformer.transformer_blocks.29.attn.to_out.0.lora.up.weight\n  [452] transformer.transformer_blocks.29.attn.to_q.lora.down.weight\n  [453] transformer.transformer_blocks.29.attn.to_q.lora.up.weight\n  [454] transformer.transformer_blocks.29.attn.to_v.lora.down.weight\n  [455] transformer.transformer_blocks.29.attn.to_v.lora.up.weight\n  [456] transformer.transformer_blocks.29.img_mlp.net.2.lora_A.weight\n  [457] transformer.transformer_blocks.29.img_mlp.net.2.lora_B.weight\n  [458] transformer.transformer_blocks.29.txt_mlp.net.2.lora_A.weight\n  [459] transformer.transformer_blocks.29.txt_mlp.net.2.lora_B.weight\n  [460] transformer.transformer_blocks.3.attn.add_k_proj.lora_A.weight\n  [461] transformer.transformer_blocks.3.attn.add_k_proj.lora_B.weight\n  [462] transformer.transformer_blocks.3.attn.add_q_proj.lora_A.weight\n  [463] transformer.transformer_blocks.3.attn.add_q_proj.lora_B.weight\n  [464] transformer.transformer_blocks.3.attn.add_v_proj.lora_A.weight\n  [465] transformer.transformer_blocks.3.attn.add_v_proj.lora_B.weight\n  [466] transformer.transformer_blocks.3.attn.to_add_out.lora_A.weight\n  [467] transformer.transformer_blocks.3.attn.to_add_out.lora_B.weight\n  [468] transformer.transformer_blocks.3.attn.to_k.lora.down.weight\n  [469] transformer.transformer_blocks.3.attn.to_k.lora.up.weight\n  [470] transformer.transformer_blocks.3.attn.to_out.0.lora.down.weight\n  [471] transformer.transformer_blocks.3.attn.to_out.0.lora.up.weight\n  [472] transformer.transformer_blocks.3.attn.to_q.lora.down.weight\n  [473] transformer.transformer_blocks.3.attn.to_q.lora.up.weight\n  [474] transformer.transformer_blocks.3.attn.to_v.lora.down.weight\n  [475] transformer.transformer_blocks.3.attn.to_v.lora.up.weight\n  [476] transformer.transformer_blocks.3.img_mlp.net.2.lora_A.weight\n  [477] transformer.transformer_blocks.3.img_mlp.net.2.lora_B.weight\n  [478] transformer.transformer_blocks.3.txt_mlp.net.2.lora_A.weight\n  [479] transformer.transformer_blocks.3.txt_mlp.net.2.lora_B.weight\n  [480] transformer.transformer_blocks.30.attn.add_k_proj.lora_A.weight\n  [481] transformer.transformer_blocks.30.attn.add_k_proj.lora_B.weight\n  [482] transformer.transformer_blocks.30.attn.add_q_proj.lora_A.weight\n  [483] transformer.transformer_blocks.30.attn.add_q_proj.lora_B.weight\n  [484] transformer.transformer_blocks.30.attn.add_v_proj.lora_A.weight\n  [485] transformer.transformer_blocks.30.attn.add_v_proj.lora_B.weight\n  [486] transformer.transformer_blocks.30.attn.to_add_out.lora_A.weight\n  [487] transformer.transformer_blocks.30.attn.to_add_out.lora_B.weight\n  [488] transformer.transformer_blocks.30.attn.to_k.lora.down.weight\n  [489] transformer.transformer_blocks.30.attn.to_k.lora.up.weight\n  [490] transformer.transformer_blocks.30.attn.to_out.0.lora.down.weight\n  [491] transformer.transformer_blocks.30.attn.to_out.0.lora.up.weight\n  [492] transformer.transformer_blocks.30.attn.to_q.lora.down.weight\n  [493] transformer.transformer_blocks.30.attn.to_q.lora.up.weight\n  [494] transformer.transformer_blocks.30.attn.to_v.lora.down.weight\n  [495] transformer.transformer_blocks.30.attn.to_v.lora.up.weight\n  [496] transformer.transformer_blocks.30.img_mlp.net.2.lora_A.weight\n  [497] transformer.transformer_blocks.30.img_mlp.net.2.lora_B.weight\n  [498] transformer.transformer_blocks.30.txt_mlp.net.2.lora_A.weight\n  [499] transformer.transformer_blocks.30.txt_mlp.net.2.lora_B.weight\n  [500] transformer.transformer_blocks.31.attn.add_k_proj.lora_A.weight\n  [501] transformer.transformer_blocks.31.attn.add_k_proj.lora_B.weight\n  [502] transformer.transformer_blocks.31.attn.add_q_proj.lora_A.weight\n  [503] transformer.transformer_blocks.31.attn.add_q_proj.lora_B.weight\n  [504] transformer.transformer_blocks.31.attn.add_v_proj.lora_A.weight\n  [505] transformer.transformer_blocks.31.attn.add_v_proj.lora_B.weight\n  [506] transformer.transformer_blocks.31.attn.to_add_out.lora_A.weight\n  [507] transformer.transformer_blocks.31.attn.to_add_out.lora_B.weight\n  [508] transformer.transformer_blocks.31.attn.to_k.lora.down.weight\n  [509] transformer.transformer_blocks.31.attn.to_k.lora.up.weight\n  [510] transformer.transformer_blocks.31.attn.to_out.0.lora.down.weight\n  [511] transformer.transformer_blocks.31.attn.to_out.0.lora.up.weight\n  [512] transformer.transformer_blocks.31.attn.to_q.lora.down.weight\n  [513] transformer.transformer_blocks.31.attn.to_q.lora.up.weight\n  [514] transformer.transformer_blocks.31.attn.to_v.lora.down.weight\n  [515] transformer.transformer_blocks.31.attn.to_v.lora.up.weight\n  [516] transformer.transformer_blocks.31.img_mlp.net.2.lora_A.weight\n  [517] transformer.transformer_blocks.31.img_mlp.net.2.lora_B.weight\n  [518] transformer.transformer_blocks.31.txt_mlp.net.2.lora_A.weight\n  [519] transformer.transformer_blocks.31.txt_mlp.net.2.lora_B.weight\n  [520] transformer.transformer_blocks.32.attn.add_k_proj.lora_A.weight\n  [521] transformer.transformer_blocks.32.attn.add_k_proj.lora_B.weight\n  [522] transformer.transformer_blocks.32.attn.add_q_proj.lora_A.weight\n  [523] transformer.transformer_blocks.32.attn.add_q_proj.lora_B.weight\n  [524] transformer.transformer_blocks.32.attn.add_v_proj.lora_A.weight\n  [525] transformer.transformer_blocks.32.attn.add_v_proj.lora_B.weight\n  [526] transformer.transformer_blocks.32.attn.to_add_out.lora_A.weight\n  [527] transformer.transformer_blocks.32.attn.to_add_out.lora_B.weight\n  [528] transformer.transformer_blocks.32.attn.to_k.lora.down.weight\n  [529] transformer.transformer_blocks.32.attn.to_k.lora.up.weight\n  [530] transformer.transformer_blocks.32.attn.to_out.0.lora.down.weight\n  [531] transformer.transformer_blocks.32.attn.to_out.0.lora.up.weight\n  [532] transformer.transformer_blocks.32.attn.to_q.lora.down.weight\n  [533] transformer.transformer_blocks.32.attn.to_q.lora.up.weight\n  [534] transformer.transformer_blocks.32.attn.to_v.lora.down.weight\n  [535] transformer.transformer_blocks.32.attn.to_v.lora.up.weight\n  [536] transformer.transformer_blocks.32.img_mlp.net.2.lora_A.weight\n  [537] transformer.transformer_blocks.32.img_mlp.net.2.lora_B.weight\n  [538] transformer.transformer_blocks.32.txt_mlp.net.2.lora_A.weight\n  [539] transformer.transformer_blocks.32.txt_mlp.net.2.lora_B.weight\n  [540] transformer.transformer_blocks.33.attn.add_k_proj.lora_A.weight\n  [541] transformer.transformer_blocks.33.attn.add_k_proj.lora_B.weight\n  [542] transformer.transformer_blocks.33.attn.add_q_proj.lora_A.weight\n  [543] transformer.transformer_blocks.33.attn.add_q_proj.lora_B.weight\n  [544] transformer.transformer_blocks.33.attn.add_v_proj.lora_A.weight\n  [545] transformer.transformer_blocks.33.attn.add_v_proj.lora_B.weight\n  [546] transformer.transformer_blocks.33.attn.to_add_out.lora_A.weight\n  [547] transformer.transformer_blocks.33.attn.to_add_out.lora_B.weight\n  [548] transformer.transformer_blocks.33.attn.to_k.lora.down.weight\n  [549] transformer.transformer_blocks.33.attn.to_k.lora.up.weight\n  [550] transformer.transformer_blocks.33.attn.to_out.0.lora.down.weight\n  [551] transformer.transformer_blocks.33.attn.to_out.0.lora.up.weight\n  [552] transformer.transformer_blocks.33.attn.to_q.lora.down.weight\n  [553] transformer.transformer_blocks.33.attn.to_q.lora.up.weight\n  [554] transformer.transformer_blocks.33.attn.to_v.lora.down.weight\n  [555] transformer.transformer_blocks.33.attn.to_v.lora.up.weight\n  [556] transformer.transformer_blocks.33.img_mlp.net.2.lora_A.weight\n  [557] transformer.transformer_blocks.33.img_mlp.net.2.lora_B.weight\n  [558] transformer.transformer_blocks.33.txt_mlp.net.2.lora_A.weight\n  [559] transformer.transformer_blocks.33.txt_mlp.net.2.lora_B.weight\n  [560] transformer.transformer_blocks.34.attn.add_k_proj.lora_A.weight\n  [561] transformer.transformer_blocks.34.attn.add_k_proj.lora_B.weight\n  [562] transformer.transformer_blocks.34.attn.add_q_proj.lora_A.weight\n  [563] transformer.transformer_blocks.34.attn.add_q_proj.lora_B.weight\n  [564] transformer.transformer_blocks.34.attn.add_v_proj.lora_A.weight\n  [565] transformer.transformer_blocks.34.attn.add_v_proj.lora_B.weight\n  [566] transformer.transformer_blocks.34.attn.to_add_out.lora_A.weight\n  [567] transformer.transformer_blocks.34.attn.to_add_out.lora_B.weight\n  [568] transformer.transformer_blocks.34.attn.to_k.lora.down.weight\n  [569] transformer.transformer_blocks.34.attn.to_k.lora.up.weight\n  [570] transformer.transformer_blocks.34.attn.to_out.0.lora.down.weight\n  [571] transformer.transformer_blocks.34.attn.to_out.0.lora.up.weight\n  [572] transformer.transformer_blocks.34.attn.to_q.lora.down.weight\n  [573] transformer.transformer_blocks.34.attn.to_q.lora.up.weight\n  [574] transformer.transformer_blocks.34.attn.to_v.lora.down.weight\n  [575] transformer.transformer_blocks.34.attn.to_v.lora.up.weight\n  [576] transformer.transformer_blocks.34.img_mlp.net.2.lora_A.weight\n  [577] transformer.transformer_blocks.34.img_mlp.net.2.lora_B.weight\n  [578] transformer.transformer_blocks.34.txt_mlp.net.2.lora_A.weight\n  [579] transformer.transformer_blocks.34.txt_mlp.net.2.lora_B.weight\n  [580] transformer.transformer_blocks.35.attn.add_k_proj.lora_A.weight\n  [581] transformer.transformer_blocks.35.attn.add_k_proj.lora_B.weight\n  [582] transformer.transformer_blocks.35.attn.add_q_proj.lora_A.weight\n  [583] transformer.transformer_blocks.35.attn.add_q_proj.lora_B.weight\n  [584] transformer.transformer_blocks.35.attn.add_v_proj.lora_A.weight\n  [585] transformer.transformer_blocks.35.attn.add_v_proj.lora_B.weight\n  [586] transformer.transformer_blocks.35.attn.to_add_out.lora_A.weight\n  [587] transformer.transformer_blocks.35.attn.to_add_out.lora_B.weight\n  [588] transformer.transformer_blocks.35.attn.to_k.lora.down.weight\n  [589] transformer.transformer_blocks.35.attn.to_k.lora.up.weight\n  [590] transformer.transformer_blocks.35.attn.to_out.0.lora.down.weight\n  [591] transformer.transformer_blocks.35.attn.to_out.0.lora.up.weight\n  [592] transformer.transformer_blocks.35.attn.to_q.lora.down.weight\n  [593] transformer.transformer_blocks.35.attn.to_q.lora.up.weight\n  [594] transformer.transformer_blocks.35.attn.to_v.lora.down.weight\n  [595] transformer.transformer_blocks.35.attn.to_v.lora.up.weight\n  [596] transformer.transformer_blocks.35.img_mlp.net.2.lora_A.weight\n  [597] transformer.transformer_blocks.35.img_mlp.net.2.lora_B.weight\n  [598] transformer.transformer_blocks.35.txt_mlp.net.2.lora_A.weight\n  [599] transformer.transformer_blocks.35.txt_mlp.net.2.lora_B.weight\n  [600] transformer.transformer_blocks.36.attn.add_k_proj.lora_A.weight\n  [601] transformer.transformer_blocks.36.attn.add_k_proj.lora_B.weight\n  [602] transformer.transformer_blocks.36.attn.add_q_proj.lora_A.weight\n  [603] transformer.transformer_blocks.36.attn.add_q_proj.lora_B.weight\n  [604] transformer.transformer_blocks.36.attn.add_v_proj.lora_A.weight\n  [605] transformer.transformer_blocks.36.attn.add_v_proj.lora_B.weight\n  [606] transformer.transformer_blocks.36.attn.to_add_out.lora_A.weight\n  [607] transformer.transformer_blocks.36.attn.to_add_out.lora_B.weight\n  [608] transformer.transformer_blocks.36.attn.to_k.lora.down.weight\n  [609] transformer.transformer_blocks.36.attn.to_k.lora.up.weight\n  [610] transformer.transformer_blocks.36.attn.to_out.0.lora.down.weight\n  [611] transformer.transformer_blocks.36.attn.to_out.0.lora.up.weight\n  [612] transformer.transformer_blocks.36.attn.to_q.lora.down.weight\n  [613] transformer.transformer_blocks.36.attn.to_q.lora.up.weight\n  [614] transformer.transformer_blocks.36.attn.to_v.lora.down.weight\n  [615] transformer.transformer_blocks.36.attn.to_v.lora.up.weight\n  [616] transformer.transformer_blocks.36.img_mlp.net.2.lora_A.weight\n  [617] transformer.transformer_blocks.36.img_mlp.net.2.lora_B.weight\n  [618] transformer.transformer_blocks.36.txt_mlp.net.2.lora_A.weight\n  [619] transformer.transformer_blocks.36.txt_mlp.net.2.lora_B.weight\n  [620] transformer.transformer_blocks.37.attn.add_k_proj.lora_A.weight\n  [621] transformer.transformer_blocks.37.attn.add_k_proj.lora_B.weight\n  [622] transformer.transformer_blocks.37.attn.add_q_proj.lora_A.weight\n  [623] transformer.transformer_blocks.37.attn.add_q_proj.lora_B.weight\n  [624] transformer.transformer_blocks.37.attn.add_v_proj.lora_A.weight\n  [625] transformer.transformer_blocks.37.attn.add_v_proj.lora_B.weight\n  [626] transformer.transformer_blocks.37.attn.to_add_out.lora_A.weight\n  [627] transformer.transformer_blocks.37.attn.to_add_out.lora_B.weight\n  [628] transformer.transformer_blocks.37.attn.to_k.lora.down.weight\n  [629] transformer.transformer_blocks.37.attn.to_k.lora.up.weight\n  [630] transformer.transformer_blocks.37.attn.to_out.0.lora.down.weight\n  [631] transformer.transformer_blocks.37.attn.to_out.0.lora.up.weight\n  [632] transformer.transformer_blocks.37.attn.to_q.lora.down.weight\n  [633] transformer.transformer_blocks.37.attn.to_q.lora.up.weight\n  [634] transformer.transformer_blocks.37.attn.to_v.lora.down.weight\n  [635] transformer.transformer_blocks.37.attn.to_v.lora.up.weight\n  [636] transformer.transformer_blocks.37.img_mlp.net.2.lora_A.weight\n  [637] transformer.transformer_blocks.37.img_mlp.net.2.lora_B.weight\n  [638] transformer.transformer_blocks.37.txt_mlp.net.2.lora_A.weight\n  [639] transformer.transformer_blocks.37.txt_mlp.net.2.lora_B.weight\n  [640] transformer.transformer_blocks.38.attn.add_k_proj.lora_A.weight\n  [641] transformer.transformer_blocks.38.attn.add_k_proj.lora_B.weight\n  [642] transformer.transformer_blocks.38.attn.add_q_proj.lora_A.weight\n  [643] transformer.transformer_blocks.38.attn.add_q_proj.lora_B.weight\n  [644] transformer.transformer_blocks.38.attn.add_v_proj.lora_A.weight\n  [645] transformer.transformer_blocks.38.attn.add_v_proj.lora_B.weight\n  [646] transformer.transformer_blocks.38.attn.to_add_out.lora_A.weight\n  [647] transformer.transformer_blocks.38.attn.to_add_out.lora_B.weight\n  [648] transformer.transformer_blocks.38.attn.to_k.lora.down.weight\n  [649] transformer.transformer_blocks.38.attn.to_k.lora.up.weight\n  [650] transformer.transformer_blocks.38.attn.to_out.0.lora.down.weight\n  [651] transformer.transformer_blocks.38.attn.to_out.0.lora.up.weight\n  [652] transformer.transformer_blocks.38.attn.to_q.lora.down.weight\n  [653] transformer.transformer_blocks.38.attn.to_q.lora.up.weight\n  [654] transformer.transformer_blocks.38.attn.to_v.lora.down.weight\n  [655] transformer.transformer_blocks.38.attn.to_v.lora.up.weight\n  [656] transformer.transformer_blocks.38.img_mlp.net.2.lora_A.weight\n  [657] transformer.transformer_blocks.38.img_mlp.net.2.lora_B.weight\n  [658] transformer.transformer_blocks.38.txt_mlp.net.2.lora_A.weight\n  [659] transformer.transformer_blocks.38.txt_mlp.net.2.lora_B.weight\n  [660] transformer.transformer_blocks.39.attn.add_k_proj.lora_A.weight\n  [661] transformer.transformer_blocks.39.attn.add_k_proj.lora_B.weight\n  [662] transformer.transformer_blocks.39.attn.add_q_proj.lora_A.weight\n  [663] transformer.transformer_blocks.39.attn.add_q_proj.lora_B.weight\n  [664] transformer.transformer_blocks.39.attn.add_v_proj.lora_A.weight\n  [665] transformer.transformer_blocks.39.attn.add_v_proj.lora_B.weight\n  [666] transformer.transformer_blocks.39.attn.to_add_out.lora_A.weight\n  [667] transformer.transformer_blocks.39.attn.to_add_out.lora_B.weight\n  [668] transformer.transformer_blocks.39.attn.to_k.lora.down.weight\n  [669] transformer.transformer_blocks.39.attn.to_k.lora.up.weight\n  [670] transformer.transformer_blocks.39.attn.to_out.0.lora.down.weight\n  [671] transformer.transformer_blocks.39.attn.to_out.0.lora.up.weight\n  [672] transformer.transformer_blocks.39.attn.to_q.lora.down.weight\n  [673] transformer.transformer_blocks.39.attn.to_q.lora.up.weight\n  [674] transformer.transformer_blocks.39.attn.to_v.lora.down.weight\n  [675] transformer.transformer_blocks.39.attn.to_v.lora.up.weight\n  [676] transformer.transformer_blocks.39.img_mlp.net.2.lora_A.weight\n  [677] transformer.transformer_blocks.39.img_mlp.net.2.lora_B.weight\n  [678] transformer.transformer_blocks.39.txt_mlp.net.2.lora_A.weight\n  [679] transformer.transformer_blocks.39.txt_mlp.net.2.lora_B.weight\n  [680] transformer.transformer_blocks.4.attn.add_k_proj.lora_A.weight\n  [681] transformer.transformer_blocks.4.attn.add_k_proj.lora_B.weight\n  [682] transformer.transformer_blocks.4.attn.add_q_proj.lora_A.weight\n  [683] transformer.transformer_blocks.4.attn.add_q_proj.lora_B.weight\n  [684] transformer.transformer_blocks.4.attn.add_v_proj.lora_A.weight\n  [685] transformer.transformer_blocks.4.attn.add_v_proj.lora_B.weight\n  [686] transformer.transformer_blocks.4.attn.to_add_out.lora_A.weight\n  [687] transformer.transformer_blocks.4.attn.to_add_out.lora_B.weight\n  [688] transformer.transformer_blocks.4.attn.to_k.lora.down.weight\n  [689] transformer.transformer_blocks.4.attn.to_k.lora.up.weight\n  [690] transformer.transformer_blocks.4.attn.to_out.0.lora.down.weight\n  [691] transformer.transformer_blocks.4.attn.to_out.0.lora.up.weight\n  [692] transformer.transformer_blocks.4.attn.to_q.lora.down.weight\n  [693] transformer.transformer_blocks.4.attn.to_q.lora.up.weight\n  [694] transformer.transformer_blocks.4.attn.to_v.lora.down.weight\n  [695] transformer.transformer_blocks.4.attn.to_v.lora.up.weight\n  [696] transformer.transformer_blocks.4.img_mlp.net.2.lora_A.weight\n  [697] transformer.transformer_blocks.4.img_mlp.net.2.lora_B.weight\n  [698] transformer.transformer_blocks.4.txt_mlp.net.2.lora_A.weight\n  [699] transformer.transformer_blocks.4.txt_mlp.net.2.lora_B.weight\n  [700] transformer.transformer_blocks.40.attn.add_k_proj.lora_A.weight\n  [701] transformer.transformer_blocks.40.attn.add_k_proj.lora_B.weight\n  [702] transformer.transformer_blocks.40.attn.add_q_proj.lora_A.weight\n  [703] transformer.transformer_blocks.40.attn.add_q_proj.lora_B.weight\n  [704] transformer.transformer_blocks.40.attn.add_v_proj.lora_A.weight\n  [705] transformer.transformer_blocks.40.attn.add_v_proj.lora_B.weight\n  [706] transformer.transformer_blocks.40.attn.to_add_out.lora_A.weight\n  [707] transformer.transformer_blocks.40.attn.to_add_out.lora_B.weight\n  [708] transformer.transformer_blocks.40.attn.to_k.lora.down.weight\n  [709] transformer.transformer_blocks.40.attn.to_k.lora.up.weight\n  [710] transformer.transformer_blocks.40.attn.to_out.0.lora.down.weight\n  [711] transformer.transformer_blocks.40.attn.to_out.0.lora.up.weight\n  [712] transformer.transformer_blocks.40.attn.to_q.lora.down.weight\n  [713] transformer.transformer_blocks.40.attn.to_q.lora.up.weight\n  [714] transformer.transformer_blocks.40.attn.to_v.lora.down.weight\n  [715] transformer.transformer_blocks.40.attn.to_v.lora.up.weight\n  [716] transformer.transformer_blocks.40.img_mlp.net.2.lora_A.weight\n  [717] transformer.transformer_blocks.40.img_mlp.net.2.lora_B.weight\n  [718] transformer.transformer_blocks.40.txt_mlp.net.2.lora_A.weight\n  [719] transformer.transformer_blocks.40.txt_mlp.net.2.lora_B.weight\n  [720] transformer.transformer_blocks.41.attn.add_k_proj.lora_A.weight\n  [721] transformer.transformer_blocks.41.attn.add_k_proj.lora_B.weight\n  [722] transformer.transformer_blocks.41.attn.add_q_proj.lora_A.weight\n  [723] transformer.transformer_blocks.41.attn.add_q_proj.lora_B.weight\n  [724] transformer.transformer_blocks.41.attn.add_v_proj.lora_A.weight\n  [725] transformer.transformer_blocks.41.attn.add_v_proj.lora_B.weight\n  [726] transformer.transformer_blocks.41.attn.to_add_out.lora_A.weight\n  [727] transformer.transformer_blocks.41.attn.to_add_out.lora_B.weight\n  [728] transformer.transformer_blocks.41.attn.to_k.lora.down.weight\n  [729] transformer.transformer_blocks.41.attn.to_k.lora.up.weight\n  [730] transformer.transformer_blocks.41.attn.to_out.0.lora.down.weight\n  [731] transformer.transformer_blocks.41.attn.to_out.0.lora.up.weight\n  [732] transformer.transformer_blocks.41.attn.to_q.lora.down.weight\n  [733] transformer.transformer_blocks.41.attn.to_q.lora.up.weight\n  [734] transformer.transformer_blocks.41.attn.to_v.lora.down.weight\n  [735] transformer.transformer_blocks.41.attn.to_v.lora.up.weight\n  [736] transformer.transformer_blocks.41.img_mlp.net.2.lora_A.weight\n  [737] transformer.transformer_blocks.41.img_mlp.net.2.lora_B.weight\n  [738] transformer.transformer_blocks.41.txt_mlp.net.2.lora_A.weight\n  [739] transformer.transformer_blocks.41.txt_mlp.net.2.lora_B.weight\n  [740] transformer.transformer_blocks.42.attn.add_k_proj.lora_A.weight\n  [741] transformer.transformer_blocks.42.attn.add_k_proj.lora_B.weight\n  [742] transformer.transformer_blocks.42.attn.add_q_proj.lora_A.weight\n  [743] transformer.transformer_blocks.42.attn.add_q_proj.lora_B.weight\n  [744] transformer.transformer_blocks.42.attn.add_v_proj.lora_A.weight\n  [745] transformer.transformer_blocks.42.attn.add_v_proj.lora_B.weight\n  [746] transformer.transformer_blocks.42.attn.to_add_out.lora_A.weight\n  [747] transformer.transformer_blocks.42.attn.to_add_out.lora_B.weight\n  [748] transformer.transformer_blocks.42.attn.to_k.lora.down.weight\n  [749] transformer.transformer_blocks.42.attn.to_k.lora.up.weight\n  [750] transformer.transformer_blocks.42.attn.to_out.0.lora.down.weight\n  [751] transformer.transformer_blocks.42.attn.to_out.0.lora.up.weight\n  [752] transformer.transformer_blocks.42.attn.to_q.lora.down.weight\n  [753] transformer.transformer_blocks.42.attn.to_q.lora.up.weight\n  [754] transformer.transformer_blocks.42.attn.to_v.lora.down.weight\n  [755] transformer.transformer_blocks.42.attn.to_v.lora.up.weight\n  [756] transformer.transformer_blocks.42.img_mlp.net.2.lora_A.weight\n  [757] transformer.transformer_blocks.42.img_mlp.net.2.lora_B.weight\n  [758] transformer.transformer_blocks.42.txt_mlp.net.2.lora_A.weight\n  [759] transformer.transformer_blocks.42.txt_mlp.net.2.lora_B.weight\n  [760] transformer.transformer_blocks.43.attn.add_k_proj.lora_A.weight\n  [761] transformer.transformer_blocks.43.attn.add_k_proj.lora_B.weight\n  [762] transformer.transformer_blocks.43.attn.add_q_proj.lora_A.weight\n  [763] transformer.transformer_blocks.43.attn.add_q_proj.lora_B.weight\n  [764] transformer.transformer_blocks.43.attn.add_v_proj.lora_A.weight\n  [765] transformer.transformer_blocks.43.attn.add_v_proj.lora_B.weight\n  [766] transformer.transformer_blocks.43.attn.to_add_out.lora_A.weight\n  [767] transformer.transformer_blocks.43.attn.to_add_out.lora_B.weight\n  [768] transformer.transformer_blocks.43.attn.to_k.lora.down.weight\n  [769] transformer.transformer_blocks.43.attn.to_k.lora.up.weight\n  [770] transformer.transformer_blocks.43.attn.to_out.0.lora.down.weight\n  [771] transformer.transformer_blocks.43.attn.to_out.0.lora.up.weight\n  [772] transformer.transformer_blocks.43.attn.to_q.lora.down.weight\n  [773] transformer.transformer_blocks.43.attn.to_q.lora.up.weight\n  [774] transformer.transformer_blocks.43.attn.to_v.lora.down.weight\n  [775] transformer.transformer_blocks.43.attn.to_v.lora.up.weight\n  [776] transformer.transformer_blocks.43.img_mlp.net.2.lora_A.weight\n  [777] transformer.transformer_blocks.43.img_mlp.net.2.lora_B.weight\n  [778] transformer.transformer_blocks.43.txt_mlp.net.2.lora_A.weight\n  [779] transformer.transformer_blocks.43.txt_mlp.net.2.lora_B.weight\n  [780] transformer.transformer_blocks.44.attn.add_k_proj.lora_A.weight\n  [781] transformer.transformer_blocks.44.attn.add_k_proj.lora_B.weight\n  [782] transformer.transformer_blocks.44.attn.add_q_proj.lora_A.weight\n  [783] transformer.transformer_blocks.44.attn.add_q_proj.lora_B.weight\n  [784] transformer.transformer_blocks.44.attn.add_v_proj.lora_A.weight\n  [785] transformer.transformer_blocks.44.attn.add_v_proj.lora_B.weight\n  [786] transformer.transformer_blocks.44.attn.to_add_out.lora_A.weight\n  [787] transformer.transformer_blocks.44.attn.to_add_out.lora_B.weight\n  [788] transformer.transformer_blocks.44.attn.to_k.lora.down.weight\n  [789] transformer.transformer_blocks.44.attn.to_k.lora.up.weight\n  [790] transformer.transformer_blocks.44.attn.to_out.0.lora.down.weight\n  [791] transformer.transformer_blocks.44.attn.to_out.0.lora.up.weight\n  [792] transformer.transformer_blocks.44.attn.to_q.lora.down.weight\n  [793] transformer.transformer_blocks.44.attn.to_q.lora.up.weight\n  [794] transformer.transformer_blocks.44.attn.to_v.lora.down.weight\n  [795] transformer.transformer_blocks.44.attn.to_v.lora.up.weight\n  [796] transformer.transformer_blocks.44.img_mlp.net.2.lora_A.weight\n  [797] transformer.transformer_blocks.44.img_mlp.net.2.lora_B.weight\n  [798] transformer.transformer_blocks.44.txt_mlp.net.2.lora_A.weight\n  [799] transformer.transformer_blocks.44.txt_mlp.net.2.lora_B.weight\n  [800] transformer.transformer_blocks.45.attn.add_k_proj.lora_A.weight\n  [801] transformer.transformer_blocks.45.attn.add_k_proj.lora_B.weight\n  [802] transformer.transformer_blocks.45.attn.add_q_proj.lora_A.weight\n  [803] transformer.transformer_blocks.45.attn.add_q_proj.lora_B.weight\n  [804] transformer.transformer_blocks.45.attn.add_v_proj.lora_A.weight\n  [805] transformer.transformer_blocks.45.attn.add_v_proj.lora_B.weight\n  [806] transformer.transformer_blocks.45.attn.to_add_out.lora_A.weight\n  [807] transformer.transformer_blocks.45.attn.to_add_out.lora_B.weight\n  [808] transformer.transformer_blocks.45.attn.to_k.lora.down.weight\n  [809] transformer.transformer_blocks.45.attn.to_k.lora.up.weight\n  [810] transformer.transformer_blocks.45.attn.to_out.0.lora.down.weight\n  [811] transformer.transformer_blocks.45.attn.to_out.0.lora.up.weight\n  [812] transformer.transformer_blocks.45.attn.to_q.lora.down.weight\n  [813] transformer.transformer_blocks.45.attn.to_q.lora.up.weight\n  [814] transformer.transformer_blocks.45.attn.to_v.lora.down.weight\n  [815] transformer.transformer_blocks.45.attn.to_v.lora.up.weight\n  [816] transformer.transformer_blocks.45.img_mlp.net.2.lora_A.weight\n  [817] transformer.transformer_blocks.45.img_mlp.net.2.lora_B.weight\n  [818] transformer.transformer_blocks.45.txt_mlp.net.2.lora_A.weight\n  [819] transformer.transformer_blocks.45.txt_mlp.net.2.lora_B.weight\n  [820] transformer.transformer_blocks.46.attn.add_k_proj.lora_A.weight\n  [821] transformer.transformer_blocks.46.attn.add_k_proj.lora_B.weight\n  [822] transformer.transformer_blocks.46.attn.add_q_proj.lora_A.weight\n  [823] transformer.transformer_blocks.46.attn.add_q_proj.lora_B.weight\n  [824] transformer.transformer_blocks.46.attn.add_v_proj.lora_A.weight\n  [825] transformer.transformer_blocks.46.attn.add_v_proj.lora_B.weight\n  [826] transformer.transformer_blocks.46.attn.to_add_out.lora_A.weight\n  [827] transformer.transformer_blocks.46.attn.to_add_out.lora_B.weight\n  [828] transformer.transformer_blocks.46.attn.to_k.lora.down.weight\n  [829] transformer.transformer_blocks.46.attn.to_k.lora.up.weight\n  [830] transformer.transformer_blocks.46.attn.to_out.0.lora.down.weight\n  [831] transformer.transformer_blocks.46.attn.to_out.0.lora.up.weight\n  [832] transformer.transformer_blocks.46.attn.to_q.lora.down.weight\n  [833] transformer.transformer_blocks.46.attn.to_q.lora.up.weight\n  [834] transformer.transformer_blocks.46.attn.to_v.lora.down.weight\n  [835] transformer.transformer_blocks.46.attn.to_v.lora.up.weight\n  [836] transformer.transformer_blocks.46.img_mlp.net.2.lora_A.weight\n  [837] transformer.transformer_blocks.46.img_mlp.net.2.lora_B.weight\n  [838] transformer.transformer_blocks.46.txt_mlp.net.2.lora_A.weight\n  [839] transformer.transformer_blocks.46.txt_mlp.net.2.lora_B.weight\n  [840] transformer.transformer_blocks.47.attn.add_k_proj.lora_A.weight\n  [841] transformer.transformer_blocks.47.attn.add_k_proj.lora_B.weight\n  [842] transformer.transformer_blocks.47.attn.add_q_proj.lora_A.weight\n  [843] transformer.transformer_blocks.47.attn.add_q_proj.lora_B.weight\n  [844] transformer.transformer_blocks.47.attn.add_v_proj.lora_A.weight\n  [845] transformer.transformer_blocks.47.attn.add_v_proj.lora_B.weight\n  [846] transformer.transformer_blocks.47.attn.to_add_out.lora_A.weight\n  [847] transformer.transformer_blocks.47.attn.to_add_out.lora_B.weight\n  [848] transformer.transformer_blocks.47.attn.to_k.lora.down.weight\n  [849] transformer.transformer_blocks.47.attn.to_k.lora.up.weight\n  [850] transformer.transformer_blocks.47.attn.to_out.0.lora.down.weight\n  [851] transformer.transformer_blocks.47.attn.to_out.0.lora.up.weight\n  [852] transformer.transformer_blocks.47.attn.to_q.lora.down.weight\n  [853] transformer.transformer_blocks.47.attn.to_q.lora.up.weight\n  [854] transformer.transformer_blocks.47.attn.to_v.lora.down.weight\n  [855] transformer.transformer_blocks.47.attn.to_v.lora.up.weight\n  [856] transformer.transformer_blocks.47.img_mlp.net.2.lora_A.weight\n  [857] transformer.transformer_blocks.47.img_mlp.net.2.lora_B.weight\n  [858] transformer.transformer_blocks.47.txt_mlp.net.2.lora_A.weight\n  [859] transformer.transformer_blocks.47.txt_mlp.net.2.lora_B.weight\n  [860] transformer.transformer_blocks.48.attn.add_k_proj.lora_A.weight\n  [861] transformer.transformer_blocks.48.attn.add_k_proj.lora_B.weight\n  [862] transformer.transformer_blocks.48.attn.add_q_proj.lora_A.weight\n  [863] transformer.transformer_blocks.48.attn.add_q_proj.lora_B.weight\n  [864] transformer.transformer_blocks.48.attn.add_v_proj.lora_A.weight\n  [865] transformer.transformer_blocks.48.attn.add_v_proj.lora_B.weight\n  [866] transformer.transformer_blocks.48.attn.to_add_out.lora_A.weight\n  [867] transformer.transformer_blocks.48.attn.to_add_out.lora_B.weight\n  [868] transformer.transformer_blocks.48.attn.to_k.lora.down.weight\n  [869] transformer.transformer_blocks.48.attn.to_k.lora.up.weight\n  [870] transformer.transformer_blocks.48.attn.to_out.0.lora.down.weight\n  [871] transformer.transformer_blocks.48.attn.to_out.0.lora.up.weight\n  [872] transformer.transformer_blocks.48.attn.to_q.lora.down.weight\n  [873] transformer.transformer_blocks.48.attn.to_q.lora.up.weight\n  [874] transformer.transformer_blocks.48.attn.to_v.lora.down.weight\n  [875] transformer.transformer_blocks.48.attn.to_v.lora.up.weight\n  [876] transformer.transformer_blocks.48.img_mlp.net.2.lora_A.weight\n  [877] transformer.transformer_blocks.48.img_mlp.net.2.lora_B.weight\n  [878] transformer.transformer_blocks.48.txt_mlp.net.2.lora_A.weight\n  [879] transformer.transformer_blocks.48.txt_mlp.net.2.lora_B.weight\n  [880] transformer.transformer_blocks.49.attn.add_k_proj.lora_A.weight\n  [881] transformer.transformer_blocks.49.attn.add_k_proj.lora_B.weight\n  [882] transformer.transformer_blocks.49.attn.add_q_proj.lora_A.weight\n  [883] transformer.transformer_blocks.49.attn.add_q_proj.lora_B.weight\n  [884] transformer.transformer_blocks.49.attn.add_v_proj.lora_A.weight\n  [885] transformer.transformer_blocks.49.attn.add_v_proj.lora_B.weight\n  [886] transformer.transformer_blocks.49.attn.to_add_out.lora_A.weight\n  [887] transformer.transformer_blocks.49.attn.to_add_out.lora_B.weight\n  [888] transformer.transformer_blocks.49.attn.to_k.lora.down.weight\n  [889] transformer.transformer_blocks.49.attn.to_k.lora.up.weight\n  [890] transformer.transformer_blocks.49.attn.to_out.0.lora.down.weight\n  [891] transformer.transformer_blocks.49.attn.to_out.0.lora.up.weight\n  [892] transformer.transformer_blocks.49.attn.to_q.lora.down.weight\n  [893] transformer.transformer_blocks.49.attn.to_q.lora.up.weight\n  [894] transformer.transformer_blocks.49.attn.to_v.lora.down.weight\n  [895] transformer.transformer_blocks.49.attn.to_v.lora.up.weight\n  [896] transformer.transformer_blocks.49.img_mlp.net.2.lora_A.weight\n  [897] transformer.transformer_blocks.49.img_mlp.net.2.lora_B.weight\n  [898] transformer.transformer_blocks.49.txt_mlp.net.2.lora_A.weight\n  [899] transformer.transformer_blocks.49.txt_mlp.net.2.lora_B.weight\n  [900] transformer.transformer_blocks.5.attn.add_k_proj.lora_A.weight\n  [901] transformer.transformer_blocks.5.attn.add_k_proj.lora_B.weight\n  [902] transformer.transformer_blocks.5.attn.add_q_proj.lora_A.weight\n  [903] transformer.transformer_blocks.5.attn.add_q_proj.lora_B.weight\n  [904] transformer.transformer_blocks.5.attn.add_v_proj.lora_A.weight\n  [905] transformer.transformer_blocks.5.attn.add_v_proj.lora_B.weight\n  [906] transformer.transformer_blocks.5.attn.to_add_out.lora_A.weight\n  [907] transformer.transformer_blocks.5.attn.to_add_out.lora_B.weight\n  [908] transformer.transformer_blocks.5.attn.to_k.lora.down.weight\n  [909] transformer.transformer_blocks.5.attn.to_k.lora.up.weight\n  [910] transformer.transformer_blocks.5.attn.to_out.0.lora.down.weight\n  [911] transformer.transformer_blocks.5.attn.to_out.0.lora.up.weight\n  [912] transformer.transformer_blocks.5.attn.to_q.lora.down.weight\n  [913] transformer.transformer_blocks.5.attn.to_q.lora.up.weight\n  [914] transformer.transformer_blocks.5.attn.to_v.lora.down.weight\n  [915] transformer.transformer_blocks.5.attn.to_v.lora.up.weight\n  [916] transformer.transformer_blocks.5.img_mlp.net.2.lora_A.weight\n  [917] transformer.transformer_blocks.5.img_mlp.net.2.lora_B.weight\n  [918] transformer.transformer_blocks.5.txt_mlp.net.2.lora_A.weight\n  [919] transformer.transformer_blocks.5.txt_mlp.net.2.lora_B.weight\n  [920] transformer.transformer_blocks.50.attn.add_k_proj.lora_A.weight\n  [921] transformer.transformer_blocks.50.attn.add_k_proj.lora_B.weight\n  [922] transformer.transformer_blocks.50.attn.add_q_proj.lora_A.weight\n  [923] transformer.transformer_blocks.50.attn.add_q_proj.lora_B.weight\n  [924] transformer.transformer_blocks.50.attn.add_v_proj.lora_A.weight\n  [925] transformer.transformer_blocks.50.attn.add_v_proj.lora_B.weight\n  [926] transformer.transformer_blocks.50.attn.to_add_out.lora_A.weight\n  [927] transformer.transformer_blocks.50.attn.to_add_out.lora_B.weight\n  [928] transformer.transformer_blocks.50.attn.to_k.lora.down.weight\n  [929] transformer.transformer_blocks.50.attn.to_k.lora.up.weight\n  [930] transformer.transformer_blocks.50.attn.to_out.0.lora.down.weight\n  [931] transformer.transformer_blocks.50.attn.to_out.0.lora.up.weight\n  [932] transformer.transformer_blocks.50.attn.to_q.lora.down.weight\n  [933] transformer.transformer_blocks.50.attn.to_q.lora.up.weight\n  [934] transformer.transformer_blocks.50.attn.to_v.lora.down.weight\n  [935] transformer.transformer_blocks.50.attn.to_v.lora.up.weight\n  [936] transformer.transformer_blocks.50.img_mlp.net.2.lora_A.weight\n  [937] transformer.transformer_blocks.50.img_mlp.net.2.lora_B.weight\n  [938] transformer.transformer_blocks.50.txt_mlp.net.2.lora_A.weight\n  [939] transformer.transformer_blocks.50.txt_mlp.net.2.lora_B.weight\n  [940] transformer.transformer_blocks.51.attn.add_k_proj.lora_A.weight\n  [941] transformer.transformer_blocks.51.attn.add_k_proj.lora_B.weight\n  [942] transformer.transformer_blocks.51.attn.add_q_proj.lora_A.weight\n  [943] transformer.transformer_blocks.51.attn.add_q_proj.lora_B.weight\n  [944] transformer.transformer_blocks.51.attn.add_v_proj.lora_A.weight\n  [945] transformer.transformer_blocks.51.attn.add_v_proj.lora_B.weight\n  [946] transformer.transformer_blocks.51.attn.to_add_out.lora_A.weight\n  [947] transformer.transformer_blocks.51.attn.to_add_out.lora_B.weight\n  [948] transformer.transformer_blocks.51.attn.to_k.lora.down.weight\n  [949] transformer.transformer_blocks.51.attn.to_k.lora.up.weight\n  [950] transformer.transformer_blocks.51.attn.to_out.0.lora.down.weight\n  [951] transformer.transformer_blocks.51.attn.to_out.0.lora.up.weight\n  [952] transformer.transformer_blocks.51.attn.to_q.lora.down.weight\n  [953] transformer.transformer_blocks.51.attn.to_q.lora.up.weight\n  [954] transformer.transformer_blocks.51.attn.to_v.lora.down.weight\n  [955] transformer.transformer_blocks.51.attn.to_v.lora.up.weight\n  [956] transformer.transformer_blocks.51.img_mlp.net.2.lora_A.weight\n  [957] transformer.transformer_blocks.51.img_mlp.net.2.lora_B.weight\n  [958] transformer.transformer_blocks.51.txt_mlp.net.2.lora_A.weight\n  [959] transformer.transformer_blocks.51.txt_mlp.net.2.lora_B.weight\n  [960] transformer.transformer_blocks.52.attn.add_k_proj.lora_A.weight\n  [961] transformer.transformer_blocks.52.attn.add_k_proj.lora_B.weight\n  [962] transformer.transformer_blocks.52.attn.add_q_proj.lora_A.weight\n  [963] transformer.transformer_blocks.52.attn.add_q_proj.lora_B.weight\n  [964] transformer.transformer_blocks.52.attn.add_v_proj.lora_A.weight\n  [965] transformer.transformer_blocks.52.attn.add_v_proj.lora_B.weight\n  [966] transformer.transformer_blocks.52.attn.to_add_out.lora_A.weight\n  [967] transformer.transformer_blocks.52.attn.to_add_out.lora_B.weight\n  [968] transformer.transformer_blocks.52.attn.to_k.lora.down.weight\n  [969] transformer.transformer_blocks.52.attn.to_k.lora.up.weight\n  [970] transformer.transformer_blocks.52.attn.to_out.0.lora.down.weight\n  [971] transformer.transformer_blocks.52.attn.to_out.0.lora.up.weight\n  [972] transformer.transformer_blocks.52.attn.to_q.lora.down.weight\n  [973] transformer.transformer_blocks.52.attn.to_q.lora.up.weight\n  [974] transformer.transformer_blocks.52.attn.to_v.lora.down.weight\n  [975] transformer.transformer_blocks.52.attn.to_v.lora.up.weight\n  [976] transformer.transformer_blocks.52.img_mlp.net.2.lora_A.weight\n  [977] transformer.transformer_blocks.52.img_mlp.net.2.lora_B.weight\n  [978] transformer.transformer_blocks.52.txt_mlp.net.2.lora_A.weight\n  [979] transformer.transformer_blocks.52.txt_mlp.net.2.lora_B.weight\n  [980] transformer.transformer_blocks.53.attn.add_k_proj.lora_A.weight\n  [981] transformer.transformer_blocks.53.attn.add_k_proj.lora_B.weight\n  [982] transformer.transformer_blocks.53.attn.add_q_proj.lora_A.weight\n  [983] transformer.transformer_blocks.53.attn.add_q_proj.lora_B.weight\n  [984] transformer.transformer_blocks.53.attn.add_v_proj.lora_A.weight\n  [985] transformer.transformer_blocks.53.attn.add_v_proj.lora_B.weight\n  [986] transformer.transformer_blocks.53.attn.to_add_out.lora_A.weight\n  [987] transformer.transformer_blocks.53.attn.to_add_out.lora_B.weight\n  [988] transformer.transformer_blocks.53.attn.to_k.lora.down.weight\n  [989] transformer.transformer_blocks.53.attn.to_k.lora.up.weight\n  [990] transformer.transformer_blocks.53.attn.to_out.0.lora.down.weight\n  [991] transformer.transformer_blocks.53.attn.to_out.0.lora.up.weight\n  [992] transformer.transformer_blocks.53.attn.to_q.lora.down.weight\n  [993] transformer.transformer_blocks.53.attn.to_q.lora.up.weight\n  [994] transformer.transformer_blocks.53.attn.to_v.lora.down.weight\n  [995] transformer.transformer_blocks.53.attn.to_v.lora.up.weight\n  [996] transformer.transformer_blocks.53.img_mlp.net.2.lora_A.weight\n  [997] transformer.transformer_blocks.53.img_mlp.net.2.lora_B.weight\n  [998] transformer.transformer_blocks.53.txt_mlp.net.2.lora_A.weight\n  [999] transformer.transformer_blocks.53.txt_mlp.net.2.lora_B.weight\n  [1000] transformer.transformer_blocks.54.attn.add_k_proj.lora_A.weight\n  [1001] transformer.transformer_blocks.54.attn.add_k_proj.lora_B.weight\n  [1002] transformer.transformer_blocks.54.attn.add_q_proj.lora_A.weight\n  [1003] transformer.transformer_blocks.54.attn.add_q_proj.lora_B.weight\n  [1004] transformer.transformer_blocks.54.attn.add_v_proj.lora_A.weight\n  [1005] transformer.transformer_blocks.54.attn.add_v_proj.lora_B.weight\n  [1006] transformer.transformer_blocks.54.attn.to_add_out.lora_A.weight\n  [1007] transformer.transformer_blocks.54.attn.to_add_out.lora_B.weight\n  [1008] transformer.transformer_blocks.54.attn.to_k.lora.down.weight\n  [1009] transformer.transformer_blocks.54.attn.to_k.lora.up.weight\n  [1010] transformer.transformer_blocks.54.attn.to_out.0.lora.down.weight\n  [1011] transformer.transformer_blocks.54.attn.to_out.0.lora.up.weight\n  [1012] transformer.transformer_blocks.54.attn.to_q.lora.down.weight\n  [1013] transformer.transformer_blocks.54.attn.to_q.lora.up.weight\n  [1014] transformer.transformer_blocks.54.attn.to_v.lora.down.weight\n  [1015] transformer.transformer_blocks.54.attn.to_v.lora.up.weight\n  [1016] transformer.transformer_blocks.54.img_mlp.net.2.lora_A.weight\n  [1017] transformer.transformer_blocks.54.img_mlp.net.2.lora_B.weight\n  [1018] transformer.transformer_blocks.54.txt_mlp.net.2.lora_A.weight\n  [1019] transformer.transformer_blocks.54.txt_mlp.net.2.lora_B.weight\n  [1020] transformer.transformer_blocks.55.attn.add_k_proj.lora_A.weight\n  [1021] transformer.transformer_blocks.55.attn.add_k_proj.lora_B.weight\n  [1022] transformer.transformer_blocks.55.attn.add_q_proj.lora_A.weight\n  [1023] transformer.transformer_blocks.55.attn.add_q_proj.lora_B.weight\n  [1024] transformer.transformer_blocks.55.attn.add_v_proj.lora_A.weight\n  [1025] transformer.transformer_blocks.55.attn.add_v_proj.lora_B.weight\n  [1026] transformer.transformer_blocks.55.attn.to_add_out.lora_A.weight\n  [1027] transformer.transformer_blocks.55.attn.to_add_out.lora_B.weight\n  [1028] transformer.transformer_blocks.55.attn.to_k.lora.down.weight\n  [1029] transformer.transformer_blocks.55.attn.to_k.lora.up.weight\n  [1030] transformer.transformer_blocks.55.attn.to_out.0.lora.down.weight\n  [1031] transformer.transformer_blocks.55.attn.to_out.0.lora.up.weight\n  [1032] transformer.transformer_blocks.55.attn.to_q.lora.down.weight\n  [1033] transformer.transformer_blocks.55.attn.to_q.lora.up.weight\n  [1034] transformer.transformer_blocks.55.attn.to_v.lora.down.weight\n  [1035] transformer.transformer_blocks.55.attn.to_v.lora.up.weight\n  [1036] transformer.transformer_blocks.55.img_mlp.net.2.lora_A.weight\n  [1037] transformer.transformer_blocks.55.img_mlp.net.2.lora_B.weight\n  [1038] transformer.transformer_blocks.55.txt_mlp.net.2.lora_A.weight\n  [1039] transformer.transformer_blocks.55.txt_mlp.net.2.lora_B.weight\n  [1040] transformer.transformer_blocks.56.attn.add_k_proj.lora_A.weight\n  [1041] transformer.transformer_blocks.56.attn.add_k_proj.lora_B.weight\n  [1042] transformer.transformer_blocks.56.attn.add_q_proj.lora_A.weight\n  [1043] transformer.transformer_blocks.56.attn.add_q_proj.lora_B.weight\n  [1044] transformer.transformer_blocks.56.attn.add_v_proj.lora_A.weight\n  [1045] transformer.transformer_blocks.56.attn.add_v_proj.lora_B.weight\n  [1046] transformer.transformer_blocks.56.attn.to_add_out.lora_A.weight\n  [1047] transformer.transformer_blocks.56.attn.to_add_out.lora_B.weight\n  [1048] transformer.transformer_blocks.56.attn.to_k.lora.down.weight\n  [1049] transformer.transformer_blocks.56.attn.to_k.lora.up.weight\n  [1050] transformer.transformer_blocks.56.attn.to_out.0.lora.down.weight\n  [1051] transformer.transformer_blocks.56.attn.to_out.0.lora.up.weight\n  [1052] transformer.transformer_blocks.56.attn.to_q.lora.down.weight\n  [1053] transformer.transformer_blocks.56.attn.to_q.lora.up.weight\n  [1054] transformer.transformer_blocks.56.attn.to_v.lora.down.weight\n  [1055] transformer.transformer_blocks.56.attn.to_v.lora.up.weight\n  [1056] transformer.transformer_blocks.56.img_mlp.net.2.lora_A.weight\n  [1057] transformer.transformer_blocks.56.img_mlp.net.2.lora_B.weight\n  [1058] transformer.transformer_blocks.56.txt_mlp.net.2.lora_A.weight\n  [1059] transformer.transformer_blocks.56.txt_mlp.net.2.lora_B.weight\n  [1060] transformer.transformer_blocks.57.attn.add_k_proj.lora_A.weight\n  [1061] transformer.transformer_blocks.57.attn.add_k_proj.lora_B.weight\n  [1062] transformer.transformer_blocks.57.attn.add_q_proj.lora_A.weight\n  [1063] transformer.transformer_blocks.57.attn.add_q_proj.lora_B.weight\n  [1064] transformer.transformer_blocks.57.attn.add_v_proj.lora_A.weight\n  [1065] transformer.transformer_blocks.57.attn.add_v_proj.lora_B.weight\n  [1066] transformer.transformer_blocks.57.attn.to_add_out.lora_A.weight\n  [1067] transformer.transformer_blocks.57.attn.to_add_out.lora_B.weight\n  [1068] transformer.transformer_blocks.57.attn.to_k.lora.down.weight\n  [1069] transformer.transformer_blocks.57.attn.to_k.lora.up.weight\n  [1070] transformer.transformer_blocks.57.attn.to_out.0.lora.down.weight\n  [1071] transformer.transformer_blocks.57.attn.to_out.0.lora.up.weight\n  [1072] transformer.transformer_blocks.57.attn.to_q.lora.down.weight\n  [1073] transformer.transformer_blocks.57.attn.to_q.lora.up.weight\n  [1074] transformer.transformer_blocks.57.attn.to_v.lora.down.weight\n  [1075] transformer.transformer_blocks.57.attn.to_v.lora.up.weight\n  [1076] transformer.transformer_blocks.57.img_mlp.net.2.lora_A.weight\n  [1077] transformer.transformer_blocks.57.img_mlp.net.2.lora_B.weight\n  [1078] transformer.transformer_blocks.57.txt_mlp.net.2.lora_A.weight\n  [1079] transformer.transformer_blocks.57.txt_mlp.net.2.lora_B.weight\n  [1080] transformer.transformer_blocks.58.attn.add_k_proj.lora_A.weight\n  [1081] transformer.transformer_blocks.58.attn.add_k_proj.lora_B.weight\n  [1082] transformer.transformer_blocks.58.attn.add_q_proj.lora_A.weight\n  [1083] transformer.transformer_blocks.58.attn.add_q_proj.lora_B.weight\n  [1084] transformer.transformer_blocks.58.attn.add_v_proj.lora_A.weight\n  [1085] transformer.transformer_blocks.58.attn.add_v_proj.lora_B.weight\n  [1086] transformer.transformer_blocks.58.attn.to_add_out.lora_A.weight\n  [1087] transformer.transformer_blocks.58.attn.to_add_out.lora_B.weight\n  [1088] transformer.transformer_blocks.58.attn.to_k.lora.down.weight\n  [1089] transformer.transformer_blocks.58.attn.to_k.lora.up.weight\n  [1090] transformer.transformer_blocks.58.attn.to_out.0.lora.down.weight\n  [1091] transformer.transformer_blocks.58.attn.to_out.0.lora.up.weight\n  [1092] transformer.transformer_blocks.58.attn.to_q.lora.down.weight\n  [1093] transformer.transformer_blocks.58.attn.to_q.lora.up.weight\n  [1094] transformer.transformer_blocks.58.attn.to_v.lora.down.weight\n  [1095] transformer.transformer_blocks.58.attn.to_v.lora.up.weight\n  [1096] transformer.transformer_blocks.58.img_mlp.net.2.lora_A.weight\n  [1097] transformer.transformer_blocks.58.img_mlp.net.2.lora_B.weight\n  [1098] transformer.transformer_blocks.58.txt_mlp.net.2.lora_A.weight\n  [1099] transformer.transformer_blocks.58.txt_mlp.net.2.lora_B.weight\n  [1100] transformer.transformer_blocks.59.attn.add_k_proj.lora_A.weight\n  [1101] transformer.transformer_blocks.59.attn.add_k_proj.lora_B.weight\n  [1102] transformer.transformer_blocks.59.attn.add_q_proj.lora_A.weight\n  [1103] transformer.transformer_blocks.59.attn.add_q_proj.lora_B.weight\n  [1104] transformer.transformer_blocks.59.attn.add_v_proj.lora_A.weight\n  [1105] transformer.transformer_blocks.59.attn.add_v_proj.lora_B.weight\n  [1106] transformer.transformer_blocks.59.attn.to_add_out.lora_A.weight\n  [1107] transformer.transformer_blocks.59.attn.to_add_out.lora_B.weight\n  [1108] transformer.transformer_blocks.59.attn.to_k.lora.down.weight\n  [1109] transformer.transformer_blocks.59.attn.to_k.lora.up.weight\n  [1110] transformer.transformer_blocks.59.attn.to_out.0.lora.down.weight\n  [1111] transformer.transformer_blocks.59.attn.to_out.0.lora.up.weight\n  [1112] transformer.transformer_blocks.59.attn.to_q.lora.down.weight\n  [1113] transformer.transformer_blocks.59.attn.to_q.lora.up.weight\n  [1114] transformer.transformer_blocks.59.attn.to_v.lora.down.weight\n  [1115] transformer.transformer_blocks.59.attn.to_v.lora.up.weight\n  [1116] transformer.transformer_blocks.59.img_mlp.net.2.lora_A.weight\n  [1117] transformer.transformer_blocks.59.img_mlp.net.2.lora_B.weight\n  [1118] transformer.transformer_blocks.59.txt_mlp.net.2.lora_A.weight\n  [1119] transformer.transformer_blocks.59.txt_mlp.net.2.lora_B.weight\n  [1120] transformer.transformer_blocks.6.attn.add_k_proj.lora_A.weight\n  [1121] transformer.transformer_blocks.6.attn.add_k_proj.lora_B.weight\n  [1122] transformer.transformer_blocks.6.attn.add_q_proj.lora_A.weight\n  [1123] transformer.transformer_blocks.6.attn.add_q_proj.lora_B.weight\n  [1124] transformer.transformer_blocks.6.attn.add_v_proj.lora_A.weight\n  [1125] transformer.transformer_blocks.6.attn.add_v_proj.lora_B.weight\n  [1126] transformer.transformer_blocks.6.attn.to_add_out.lora_A.weight\n  [1127] transformer.transformer_blocks.6.attn.to_add_out.lora_B.weight\n  [1128] transformer.transformer_blocks.6.attn.to_k.lora.down.weight\n  [1129] transformer.transformer_blocks.6.attn.to_k.lora.up.weight\n  [1130] transformer.transformer_blocks.6.attn.to_out.0.lora.down.weight\n  [1131] transformer.transformer_blocks.6.attn.to_out.0.lora.up.weight\n  [1132] transformer.transformer_blocks.6.attn.to_q.lora.down.weight\n  [1133] transformer.transformer_blocks.6.attn.to_q.lora.up.weight\n  [1134] transformer.transformer_blocks.6.attn.to_v.lora.down.weight\n  [1135] transformer.transformer_blocks.6.attn.to_v.lora.up.weight\n  [1136] transformer.transformer_blocks.6.img_mlp.net.2.lora_A.weight\n  [1137] transformer.transformer_blocks.6.img_mlp.net.2.lora_B.weight\n  [1138] transformer.transformer_blocks.6.txt_mlp.net.2.lora_A.weight\n  [1139] transformer.transformer_blocks.6.txt_mlp.net.2.lora_B.weight\n  [1140] transformer.transformer_blocks.7.attn.add_k_proj.lora_A.weight\n  [1141] transformer.transformer_blocks.7.attn.add_k_proj.lora_B.weight\n  [1142] transformer.transformer_blocks.7.attn.add_q_proj.lora_A.weight\n  [1143] transformer.transformer_blocks.7.attn.add_q_proj.lora_B.weight\n  [1144] transformer.transformer_blocks.7.attn.add_v_proj.lora_A.weight\n  [1145] transformer.transformer_blocks.7.attn.add_v_proj.lora_B.weight\n  [1146] transformer.transformer_blocks.7.attn.to_add_out.lora_A.weight\n  [1147] transformer.transformer_blocks.7.attn.to_add_out.lora_B.weight\n  [1148] transformer.transformer_blocks.7.attn.to_k.lora.down.weight\n  [1149] transformer.transformer_blocks.7.attn.to_k.lora.up.weight\n  [1150] transformer.transformer_blocks.7.attn.to_out.0.lora.down.weight\n  [1151] transformer.transformer_blocks.7.attn.to_out.0.lora.up.weight\n  [1152] transformer.transformer_blocks.7.attn.to_q.lora.down.weight\n  [1153] transformer.transformer_blocks.7.attn.to_q.lora.up.weight\n  [1154] transformer.transformer_blocks.7.attn.to_v.lora.down.weight\n  [1155] transformer.transformer_blocks.7.attn.to_v.lora.up.weight\n  [1156] transformer.transformer_blocks.7.img_mlp.net.2.lora_A.weight\n  [1157] transformer.transformer_blocks.7.img_mlp.net.2.lora_B.weight\n  [1158] transformer.transformer_blocks.7.txt_mlp.net.2.lora_A.weight\n  [1159] transformer.transformer_blocks.7.txt_mlp.net.2.lora_B.weight\n  [1160] transformer.transformer_blocks.8.attn.add_k_proj.lora_A.weight\n  [1161] transformer.transformer_blocks.8.attn.add_k_proj.lora_B.weight\n  [1162] transformer.transformer_blocks.8.attn.add_q_proj.lora_A.weight\n  [1163] transformer.transformer_blocks.8.attn.add_q_proj.lora_B.weight\n  [1164] transformer.transformer_blocks.8.attn.add_v_proj.lora_A.weight\n  [1165] transformer.transformer_blocks.8.attn.add_v_proj.lora_B.weight\n  [1166] transformer.transformer_blocks.8.attn.to_add_out.lora_A.weight\n  [1167] transformer.transformer_blocks.8.attn.to_add_out.lora_B.weight\n  [1168] transformer.transformer_blocks.8.attn.to_k.lora.down.weight\n  [1169] transformer.transformer_blocks.8.attn.to_k.lora.up.weight\n  [1170] transformer.transformer_blocks.8.attn.to_out.0.lora.down.weight\n  [1171] transformer.transformer_blocks.8.attn.to_out.0.lora.up.weight\n  [1172] transformer.transformer_blocks.8.attn.to_q.lora.down.weight\n  [1173] transformer.transformer_blocks.8.attn.to_q.lora.up.weight\n  [1174] transformer.transformer_blocks.8.attn.to_v.lora.down.weight\n  [1175] transformer.transformer_blocks.8.attn.to_v.lora.up.weight\n  [1176] transformer.transformer_blocks.8.img_mlp.net.2.lora_A.weight\n  [1177] transformer.transformer_blocks.8.img_mlp.net.2.lora_B.weight\n  [1178] transformer.transformer_blocks.8.txt_mlp.net.2.lora_A.weight\n  [1179] transformer.transformer_blocks.8.txt_mlp.net.2.lora_B.weight\n  [1180] transformer.transformer_blocks.9.attn.add_k_proj.lora_A.weight\n  [1181] transformer.transformer_blocks.9.attn.add_k_proj.lora_B.weight\n  [1182] transformer.transformer_blocks.9.attn.add_q_proj.lora_A.weight\n  [1183] transformer.transformer_blocks.9.attn.add_q_proj.lora_B.weight\n  [1184] transformer.transformer_blocks.9.attn.add_v_proj.lora_A.weight\n  [1185] transformer.transformer_blocks.9.attn.add_v_proj.lora_B.weight\n  [1186] transformer.transformer_blocks.9.attn.to_add_out.lora_A.weight\n  [1187] transformer.transformer_blocks.9.attn.to_add_out.lora_B.weight\n  [1188] transformer.transformer_blocks.9.attn.to_k.lora.down.weight\n  [1189] transformer.transformer_blocks.9.attn.to_k.lora.up.weight\n  [1190] transformer.transformer_blocks.9.attn.to_out.0.lora.down.weight\n  [1191] transformer.transformer_blocks.9.attn.to_out.0.lora.up.weight\n  [1192] transformer.transformer_blocks.9.attn.to_q.lora.down.weight\n  [1193] transformer.transformer_blocks.9.attn.to_q.lora.up.weight\n  [1194] transformer.transformer_blocks.9.attn.to_v.lora.down.weight\n  [1195] transformer.transformer_blocks.9.attn.to_v.lora.up.weight\n  [1196] transformer.transformer_blocks.9.img_mlp.net.2.lora_A.weight\n  [1197] transformer.transformer_blocks.9.img_mlp.net.2.lora_B.weight\n  [1198] transformer.transformer_blocks.9.txt_mlp.net.2.lora_A.weight\n  [1199] transformer.transformer_blocks.9.txt_mlp.net.2.lora_B.weight"
      ]
    },
    {
      "id": 7,
      "type": "UNETLoader",
      "pos": [
        537.7002563476562,
        83.41088104248047
      ],
      "size": [
        401.19989013671875,
        82
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "unet_name",
          "name": "unet_name",
          "type": "COMBO",
          "widget": {
            "name": "unet_name"
          },
          "link": null
        },
        {
          "localized_name": "weight_dtype",
          "name": "weight_dtype",
          "type": "COMBO",
          "widget": {
            "name": "weight_dtype"
          },
          "link": null
        }
      ],
      "outputs": [
        {
          "localized_name": "MODEL",
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            5
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "UNETLoader"
      },
      "widgets_values": [
        "qwen_image_fp8_e4m3fn.safetensors",
        "default"
      ]
    },
    {
      "id": 3,
      "type": "MergeLoraToModel",
      "pos": [
        999.0399169921875,
        211.16009521484375
      ],
      "size": [
        270,
        122
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "model",
          "name": "model",
          "type": "MODEL",
          "link": 5
        },
        {
          "localized_name": "lora",
          "name": "lora",
          "type": "LORA",
          "link": 2
        },
        {
          "localized_name": "clip",
          "name": "clip",
          "shape": 7,
          "type": "CLIP",
          "link": null
        },
        {
          "localized_name": "strength_model",
          "name": "strength_model",
          "type": "FLOAT",
          "widget": {
            "name": "strength_model"
          },
          "link": null
        },
        {
          "localized_name": "strength_clip",
          "name": "strength_clip",
          "shape": 7,
          "type": "FLOAT",
          "widget": {
            "name": "strength_clip"
          },
          "link": null
        }
      ],
      "outputs": [
        {
          "localized_name": "MODEL",
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            6
          ]
        },
        {
          "localized_name": "CLIP",
          "name": "CLIP",
          "type": "CLIP",
          "links": null
        }
      ],
      "properties": {
        "aux_id": "lrzjason/Comfyui-LoraUtils",
        "ver": "f6db1368facc26d491f90015d620f7b2b8e0c9f9",
        "Node name for S&R": "MergeLoraToModel"
      },
      "widgets_values": [
        1,
        1
      ]
    },
    {
      "id": 8,
      "type": "KSampler",
      "pos": [
        1319.7801513671875,
        209.49090576171875
      ],
      "size": [
        270,
        262
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {
          "localized_name": "model",
          "name": "model",
          "type": "MODEL",
          "link": 6
        },
        {
          "localized_name": "positive",
          "name": "positive",
          "type": "CONDITIONING",
          "link": null
        },
        {
          "localized_name": "negative",
          "name": "negative",
          "type": "CONDITIONING",
          "link": null
        },
        {
          "localized_name": "latent_image",
          "name": "latent_image",
          "type": "LATENT",
          "link": null
        },
        {
          "localized_name": "seed",
          "name": "seed",
          "type": "INT",
          "widget": {
            "name": "seed"
          },
          "link": null
        },
        {
          "localized_name": "steps",
          "name": "steps",
          "type": "INT",
          "widget": {
            "name": "steps"
          },
          "link": null
        },
        {
          "localized_name": "cfg",
          "name": "cfg",
          "type": "FLOAT",
          "widget": {
            "name": "cfg"
          },
          "link": null
        },
        {
          "localized_name": "sampler_name",
          "name": "sampler_name",
          "type": "COMBO",
          "widget": {
            "name": "sampler_name"
          },
          "link": null
        },
        {
          "localized_name": "scheduler",
          "name": "scheduler",
          "type": "COMBO",
          "widget": {
            "name": "scheduler"
          },
          "link": null
        },
        {
          "localized_name": "denoise",
          "name": "denoise",
          "type": "FLOAT",
          "widget": {
            "name": "denoise"
          },
          "link": null
        }
      ],
      "outputs": [
        {
          "localized_name": "LATENT",
          "name": "LATENT",
          "type": "LATENT",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        0,
        "randomize",
        20,
        8,
        "euler",
        "simple",
        1
      ]
    }
  ],
  "links": [
    [
      1,
      1,
      0,
      2,
      0,
      "LORA"
    ],
    [
      2,
      2,
      0,
      3,
      1,
      "LORA"
    ],
    [
      3,
      1,
      0,
      5,
      0,
      "LORA"
    ],
    [
      4,
      5,
      0,
      6,
      0,
      "*"
    ],
    [
      5,
      7,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      6,
      3,
      0,
      8,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8264462809917354,
      "offset": [
        -36.565913663747956,
        -26.032042576688617
      ]
    }
  },
  "version": 0.4
}